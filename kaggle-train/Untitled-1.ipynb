{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 17:13:22.958157: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-24 17:13:23.703883: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 28, 40)            7840      \n",
      " al)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1120)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                11210     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19050 (74.41 KB)\n",
      "Trainable params: 19050 (74.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 17:13:24.556089: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-07-24 17:13:24.556117: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: r2d2\n",
      "2023-07-24 17:13:24.556122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: r2d2\n",
      "2023-07-24 17:13:24.556170: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.54.3\n",
      "2023-07-24 17:13:24.556185: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.54.3\n",
      "2023-07-24 17:13:24.556190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.54.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "inputs=tf.keras.layers.Input(shape=(28, 28), name='input')\n",
    "#lstm= tf.keras.layers.LSTM(20, return_sequences=True)\n",
    "lstmcell=tf.keras.layers.LSTMCell(20)\n",
    "lstm = tf.keras.layers.RNN(lstmcell,return_sequences=True)\n",
    "\n",
    "x=tf.keras.layers.Bidirectional(lstm)(inputs)\n",
    "\n",
    "x=tf.keras.layers.Flatten()(x)\n",
    "outputs=tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='output')(x)\n",
    "model=tf.keras.Model(inputs=inputs,outputs=outputs)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: keras_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: keras_lstm/assets\n"
     ]
    }
   ],
   "source": [
    "class InferModel(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    @tf.function(\n",
    "        input_signature=[tf.TensorSpec(shape=(1,28,28), dtype=tf.float32, name=\"inputs\")]\n",
    "    )\n",
    "    def __call__(self, inputs):\n",
    "        return self.model(inputs)\n",
    "        #return {\"outputs\": outputs}\n",
    "\n",
    "MODEL_DIR = \"keras_lstm\"\n",
    "infer=InferModel(model)\n",
    "tf.saved_model.save(infer,MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 17:13:27.065286: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-07-24 17:13:27.065310: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-07-24 17:13:27.065844: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: keras_lstm\n",
      "2023-07-24 17:13:27.069876: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-07-24 17:13:27.069888: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: keras_lstm\n",
      "2023-07-24 17:13:27.077494: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-07-24 17:13:27.079720: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-07-24 17:13:27.108084: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: keras_lstm\n",
      "2023-07-24 17:13:27.126840: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 60997 microseconds.\n",
      "2023-07-24 17:13:27.146708: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-24 17:13:27.201625: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 0.052 M  ops, equivalently 0.026 M  MACs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "#converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = converter.convert()\n",
    "with open(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
