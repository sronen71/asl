{"cells":[{"cell_type":"markdown","metadata":{"id":"ENYLFLzurs3S"},"source":["# For Colab"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"agm4BN62kwwE"},"outputs":[],"source":["%colors nocolor\n","import os\n","IN_COLAB = 'COLAB_GPU' in os.environ\n","if IN_COLAB:\n","  from google.colab import auth,drive\n","  auth.authenticate_user()\n","  drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"TB_VhXDvhCT2"},"outputs":[],"source":["!mkdir -p /kaggle/working\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36435,"status":"ok","timestamp":1691904797151,"user":{"displayName":"Shai Ronen","userId":"11425665314369101818"},"user_tz":360},"id":"Asq1MGhs41ZX","outputId":"9309f99a-9a6a-4159-c111-d77495a815af"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-08-16 11:42:32.215358: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-08-16 11:42:32.961225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"name":"stdout","output_type":"stream","text":["Not using TPU\n"]}],"source":["import tensorflow as tf\n","tf.debugging.disable_traceback_filtering()\n","\n","tpu_strategy=None\n","try:\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n","\n","  tf.config.experimental_connect_to_cluster(tpu)\n","  tf.tpu.experimental.initialize_tpu_system(tpu)\n","  tpu_strategy = tf.distribute.TPUStrategy(tpu)\n","\n","except ValueError:\n","  print(\"Not using TPU\")\n","  #raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n","\n","\n","#from tensorflow.python.framework.ops import disable_eager_execution\n","#disable_eager_execution()  # LSTM layer can't use bfloat16 unless we do this."]},{"cell_type":"markdown","metadata":{"id":"Z-x7GxsSYi1y"},"source":["\n","# Import the libraries"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12334,"status":"ok","timestamp":1691904809445,"user":{"displayName":"Shai Ronen","userId":"11425665314369101818"},"user_tz":360},"id":"eoljCzzvYi1z","outputId":"6708f0f9-104c-4c25-8aa2-8e4d5a204316"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n","Requirement already satisfied: tensorflow-addons in /home/sronen/code/.venv/lib/python3.10/site-packages (0.21.0)\n","Requirement already satisfied: packaging in /home/sronen/code/.venv/lib/python3.10/site-packages (from tensorflow-addons) (23.0)\n","Requirement already satisfied: typeguard<3.0.0,>=2.7 in /home/sronen/code/.venv/lib/python3.10/site-packages (from tensorflow-addons) (2.13.3)\n"]},{"name":"stderr","output_type":"stream","text":["/home/sronen/code/.venv/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["\n","!pip install tensorflow-addons\n","import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import random\n","import psutil\n","import glob\n","import gc\n","import math\n","\n","import tensorflow_addons as tfa\n","#from tensorflow.python.framework.ops import disable_eager_execution\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"UV3hsk-bYi1z"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-08-16 11:42:38.202471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-08-16 11:42:38.228294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-08-16 11:42:38.228489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"]}],"source":["gpus = tf.config.list_physical_devices(\"GPU\")\n","for gpu in gpus:\n","    tf.config.experimental.set_memory_growth(gpu, True)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1691904809638,"user":{"displayName":"Shai Ronen","userId":"11425665314369101818"},"user_tz":360},"id":"rZpjjT02Yi10","outputId":"04692527-074c-477c-80b6-e6cf4e4f5d82"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow v2.13.0\n"]}],"source":["print(\"TensorFlow v\" + tf.__version__)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"0gUj7mAgYi10"},"outputs":[],"source":["class MemoryUsageCallbackExtended(tf.keras.callbacks.Callback):\n","    \"\"\"Monitor memory usage on epoch begin and end, collect garbage\"\"\"\n","\n","    # def on_epoch_begin(self, epoch, logs=None):\n","    #    print(\"**Epoch {}**\".format(epoch))\n","    #    print(\n","    #        f\"Memory usage on epoch begin: {int(psutil.Process(os.getpid()).memory_info().rss)/1e9:.2f GB}\"\n","    #    )\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        print(\n","            f\"Memory usage on epoch end: {int(psutil.Process(os.getpid()).memory_info().rss)/1e9:.2f} GB\"\n","        )\n","        gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"eErQkrlpYi11"},"source":["\n","# Scheduler"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"umV9OdZCYi11"},"outputs":[],"source":["\n","class CosineDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    \"\"\"A LearningRateSchedule that uses a cosine decay with optional warmup.\n","\n","    See [Loshchilov & Hutter, ICLR2016](https://arxiv.org/abs/1608.03983),\n","    SGDR: Stochastic Gradient Descent with Warm Restarts.\n","\n","    For the idea of a linear warmup of our learning rate,\n","    see [Goyal et al.](https://arxiv.org/pdf/1706.02677.pdf).\n","\n","    When we begin training a model, we often want an initial increase in our\n","    learning rate followed by a decay. If `warmup_target` is an int, this\n","    schedule applies a linear increase per optimizer step to our learning rate\n","    from `initial_learning_rate` to `warmup_target` for a duration of\n","    `warmup_steps`. Afterwards, it applies a cosine decay function taking our\n","    learning rate from `warmup_target` to `alpha` for a duration of\n","    `decay_steps`. If `warmup_target` is None we skip warmup and our decay\n","    will take our learning rate from `initial_learning_rate` to `alpha`.\n","    It requires a `step` value to  compute the learning rate. You can\n","    just pass a TensorFlow variable that you increment at each training step.\n","\n","    The schedule is a 1-arg callable that produces a warmup followed by a\n","    decayed learning rate when passed the current optimizer step. This can be\n","    useful for changing the learning rate value across different invocations of\n","    optimizer functions.\n","\n","    Our warmup is computed as:\n","\n","    ```python\n","    def warmup_learning_rate(step):\n","        completed_fraction = step / warmup_steps\n","        total_delta = target_warmup - initial_learning_rate\n","        return completed_fraction * total_delta\n","    ```\n","\n","    And our decay is computed as:\n","\n","    ```python\n","    if warmup_target is None:\n","        initial_decay_lr = initial_learning_rate\n","    else:\n","        initial_decay_lr = warmup_target\n","\n","    def decayed_learning_rate(step):\n","        step = min(step, decay_steps)\n","        cosine_decay = 0.5 * (1 + cos(pi * step / decay_steps))\n","        decayed = (1 - alpha) * cosine_decay + alpha\n","        return initial_decay_lr * decayed\n","    ```\n","\n","    Example usage without warmup:\n","\n","    ```python\n","    decay_steps = 1000\n","    initial_learning_rate = 0.1\n","    lr_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n","        initial_learning_rate, decay_steps)\n","    ```\n","\n","    Example usage with warmup:\n","\n","    ```python\n","    decay_steps = 1000\n","    initial_learning_rate = 0\n","    warmup_steps = 1000\n","    target_learning_rate = 0.1\n","    lr_warmup_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(\n","        initial_learning_rate, decay_steps, warmup_target=target_learning_rate,\n","        warmup_steps=warmup_steps\n","    )\n","    ```\n","\n","    You can pass this schedule directly into a `tf.keras.optimizers.Optimizer`\n","    as the learning rate. The learning rate schedule is also serializable and\n","    deserializable using `tf.keras.optimizers.schedules.serialize` and\n","    `tf.keras.optimizers.schedules.deserialize`.\n","\n","    Returns:\n","      A 1-arg callable learning rate schedule that takes the current optimizer\n","      step and outputs the decayed learning rate, a scalar `Tensor` of the same\n","      type as `initial_learning_rate`.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        initial_learning_rate,\n","        decay_steps,\n","        alpha=0.0,\n","        name=None,\n","        warmup_target=None,\n","        warmup_steps=0,\n","    ):\n","        \"\"\"Applies cosine decay to the learning rate.\n","\n","        Args:\n","          initial_learning_rate: A scalar `float32` or `float64` `Tensor` or a\n","            Python int. The initial learning rate.\n","          decay_steps: A scalar `int32` or `int64` `Tensor` or a Python int.\n","            Number of steps to decay over.\n","          alpha: A scalar `float32` or `float64` `Tensor` or a Python int.\n","            Minimum learning rate value for decay as a fraction of\n","            `initial_learning_rate`.\n","          name: String. Optional name of the operation.  Defaults to\n","            'CosineDecay'.\n","          warmup_target: None or a scalar `float32` or `float64` `Tensor` or a\n","            Python int. The target learning rate for our warmup phase. Will cast\n","            to the `initial_learning_rate` datatype. Setting to None will skip\n","            warmup and begins decay phase from `initial_learning_rate`.\n","            Otherwise scheduler will warmup from `initial_learning_rate` to\n","            `warmup_target`.\n","          warmup_steps: A scalar `int32` or `int64` `Tensor` or a Python int.\n","            Number of steps to warmup over.\n","        \"\"\"\n","        super().__init__()\n","\n","        self.initial_learning_rate = initial_learning_rate\n","        self.decay_steps = decay_steps\n","        self.alpha = alpha\n","        self.name = name\n","        self.warmup_steps = warmup_steps\n","        self.warmup_target = warmup_target\n","\n","    def _decay_function(self, step, decay_steps, decay_from_lr, dtype):\n","        with tf.name_scope(self.name or \"CosineDecay\"):\n","            completed_fraction = step / decay_steps\n","            tf_pi = tf.constant(math.pi, dtype=dtype)\n","            cosine_decayed = 0.5 * (1.0 + tf.cos(tf_pi * completed_fraction))\n","            decayed = (1 - self.alpha) * cosine_decayed + self.alpha\n","            return tf.multiply(decay_from_lr, decayed)\n","\n","    def _warmup_function(self, step, warmup_steps, warmup_target, initial_learning_rate):\n","        with tf.name_scope(self.name or \"CosineDecay\"):\n","            completed_fraction = step / warmup_steps\n","            total_step_delta = warmup_target - initial_learning_rate\n","            return total_step_delta * completed_fraction + initial_learning_rate\n","\n","    def __call__(self, step):\n","        with tf.name_scope(self.name or \"CosineDecay\"):\n","            initial_learning_rate = tf.convert_to_tensor(\n","                self.initial_learning_rate, name=\"initial_learning_rate\"\n","            )\n","            dtype = initial_learning_rate.dtype\n","            decay_steps = tf.cast(self.decay_steps, dtype)\n","            global_step_recomp = tf.cast(step, dtype)\n","\n","            if self.warmup_target is None:\n","                global_step_recomp = tf.minimum(global_step_recomp, decay_steps)\n","                return self._decay_function(\n","                    global_step_recomp,\n","                    decay_steps,\n","                    initial_learning_rate,\n","                    dtype,\n","                )\n","\n","            warmup_target = tf.cast(self.warmup_target, dtype)\n","            warmup_steps = tf.cast(self.warmup_steps, dtype)\n","\n","            global_step_recomp = tf.minimum(global_step_recomp, decay_steps + warmup_steps)\n","\n","            return tf.cond(\n","                global_step_recomp < warmup_steps,\n","                lambda: self._warmup_function(\n","                    global_step_recomp,\n","                    warmup_steps,\n","                    warmup_target,\n","                    initial_learning_rate,\n","                ),\n","                lambda: self._decay_function(\n","                    global_step_recomp - warmup_steps,\n","                    decay_steps,\n","                    warmup_target,\n","                    dtype,\n","                ),\n","            )\n","\n","    def get_config(self):\n","        return {\n","            \"initial_learning_rate\": self.initial_learning_rate,\n","            \"decay_steps\": self.decay_steps,\n","            \"alpha\": self.alpha,\n","            \"name\": self.name,\n","            \"warmup_target\": self.warmup_target,\n","            \"warmup_steps\": self.warmup_steps,\n","        }\n"]},{"cell_type":"markdown","metadata":{"id":"Vh1J_bDCYi13"},"source":["# Constants"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"5icpG0BeYi13"},"outputs":[],"source":["def get_char_dict():\n","    char_dict = {\n","        \" \": 0,\n","        \"!\": 1,\n","        \"#\": 2,\n","        \"$\": 3,\n","        \"%\": 4,\n","        \"&\": 5,\n","        \"'\": 6,\n","        \"(\": 7,\n","        \")\": 8,\n","        \"*\": 9,\n","        \"+\": 10,\n","        \",\": 11,\n","        \"-\": 12,\n","        \".\": 13,\n","        \"/\": 14,\n","        \"0\": 15,\n","        \"1\": 16,\n","        \"2\": 17,\n","        \"3\": 18,\n","        \"4\": 19,\n","        \"5\": 20,\n","        \"6\": 21,\n","        \"7\": 22,\n","        \"8\": 23,\n","        \"9\": 24,\n","        \":\": 25,\n","        \";\": 26,\n","        \"=\": 27,\n","        \"?\": 28,\n","        \"@\": 29,\n","        \"[\": 30,\n","        \"_\": 31,\n","        \"a\": 32,\n","        \"b\": 33,\n","        \"c\": 34,\n","        \"d\": 35,\n","        \"e\": 36,\n","        \"f\": 37,\n","        \"g\": 38,\n","        \"h\": 39,\n","        \"i\": 40,\n","        \"j\": 41,\n","        \"k\": 42,\n","        \"l\": 43,\n","        \"m\": 44,\n","        \"n\": 45,\n","        \"o\": 46,\n","        \"p\": 47,\n","        \"q\": 48,\n","        \"r\": 49,\n","        \"s\": 50,\n","        \"t\": 51,\n","        \"u\": 52,\n","        \"v\": 53,\n","        \"w\": 54,\n","        \"x\": 55,\n","        \"y\": 56,\n","        \"z\": 57,\n","        \"~\": 58,\n","    }\n","    char_dict[\"P\"] = 59\n","    #char_dict[\"SOS\"] = 60\n","    #char_dict[\"EOS\"] = 61\n","    return char_dict\n","\n","\n","class Constants:\n","    ROWS_PER_FRAME = 543\n","    MAX_STRING_LEN = 50\n","    INPUT_PAD = -100.0\n","    char_dict = get_char_dict()\n","    LABEL_PAD = char_dict[\"P\"]\n","    inv_dict = {v: k for k, v in char_dict.items()}\n","    NOSE = [1, 2, 98, 327]\n","\n","    REYE = [33, 7, 163, 144, 145, 153, 154, 155, 133, 246, 161, 160, 159, 158, 157, 173]\n","    LEYE = [263, 249, 390, 373, 374, 380, 381, 382, 362, 466, 388, 387, 386, 385, 384, 398]\n","\n","    LHAND = list(range(468, 489))\n","    RHAND = list(range(522, 543))\n","\n","    LNOSE = [98]\n","    RNOSE = [327]\n","\n","    LLIP = [84, 181, 91, 146, 61, 185, 40, 39, 37, 87, 178, 88, 95, 78, 191, 80, 81, 82]\n","    RLIP = [\n","        314,\n","        405,\n","        321,\n","        375,\n","        291,\n","        409,\n","        270,\n","        269,\n","        267,\n","        317,\n","        402,\n","        318,\n","        324,\n","        308,\n","        415,\n","        310,\n","        311,\n","        312,\n","    ]\n","    POSE = [500, 502, 504, 501, 503, 505, 512, 513]\n","    LPOSE = [513, 505, 503, 501]\n","    RPOSE = [512, 504, 502, 500]\n","\n","    POINT_LANDMARKS_PARTS = [LHAND, RHAND, LLIP, RLIP, LPOSE, RPOSE, NOSE, REYE, LEYE]\n","    # POINT_LANDMARKS_PARTS = [LHAND, RHAND, NOSE]\n","    POINT_LANDMARKS = [item for sublist in POINT_LANDMARKS_PARTS for item in sublist]\n","    parts = {\n","        \"LLIP\": LLIP,\n","        \"RLIP\": RLIP,\n","        \"LHAND\": LHAND,\n","        \"RHAND\": RHAND,\n","        \"LPOSE\": LPOSE,\n","        \"RPOSE\": RPOSE,\n","        \"LNOSE\": LNOSE,\n","        \"RNOSE\": RNOSE,\n","        \"REYE\": REYE,\n","        \"LEYE\": LEYE,\n","    }\n","\n","    LANDMARK_INDICES = {}  # type: ignore\n","    for part in parts:\n","        LANDMARK_INDICES[part] = []\n","        for landmark in parts[part]:\n","            if landmark in POINT_LANDMARKS:\n","                LANDMARK_INDICES[part].append(POINT_LANDMARKS.index(landmark))\n","\n","    CENTER_LANDMARKS = LNOSE + RNOSE\n","    CENTER_INDICES = LANDMARK_INDICES[\"LNOSE\"] + LANDMARK_INDICES[\"RNOSE\"]\n","\n","    NUM_NODES = len(POINT_LANDMARKS)\n","    NUM_INPUT_FEATURES = 2 * NUM_NODES # (x,y)\n","    CHANNELS = 6 * NUM_NODES #(x,y,dx,dy,dx2,dy2)\n"]},{"cell_type":"markdown","metadata":{"id":"MMEA9LflYi14"},"source":["# Utils"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"P-kprZ1_Yi14"},"outputs":[],"source":["\n","# Seed all random number generators\n","def seed_everything(seed=42):\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","\n","def selected_columns(file_example):\n","    df = pd.read_parquet(file_example)\n","    selected_x = df.columns[[x + 1 for x in Constants.POINT_LANDMARKS]].tolist()\n","    selected_y = [c.replace(\"x\", \"y\") for c in selected_x]\n","    selected = []\n","    for i in range(Constants.NUM_NODES):\n","        selected.append(selected_x[i])\n","        selected.append(selected_y[i])\n","    return selected  # x1,y1,x2,y2,...\n","\n","\n","\n","def num_to_char_fn(y):\n","    return [Constants.inv_dict.get(x, \"\") for x in y]\n","\n","\n","# A callback class to output a few transcriptions during training\n","class CallbackEval(tf.keras.callbacks.Callback):\n","    \"\"\"Displays a batch of outputs after every epoch.\"\"\"\n","\n","    def __init__(self, model, dataset):\n","        super().__init__()\n","        self.dataset = dataset\n","        self.model = model\n","\n","    def on_epoch_end(self, epoch: int, logs=None):\n","        predictions = []\n","        targets = []\n","        for batch in self.dataset:\n","            X, y = batch\n","            batch_predictions = self.model(X)\n","            batch_predictions = decode_batch_predictions(batch_predictions)\n","            predictions.extend(batch_predictions)\n","            for label in y:\n","                label = \"\".join(num_to_char_fn(label.numpy()))\n","                targets.append(label)\n","        print(\"-\" * 100)\n","        # for i in np.random.randint(0, len(predictions), 2):\n","        for i in range(10):\n","            print(f\"Target    : {targets[i]}\")\n","            print(f\"Prediction: {predictions[i]}, len: {len(predictions[i])}\")\n","            print(\"-\" * 100)\n","\n","\n","def decode_phrase(pred):\n","    # decode cts prediction by prunning\n","    # (T,CHAR_NUMS)\n","    x = tf.argmax(pred, axis=1)\n","    paddings = tf.constant(\n","        [\n","            [0, 1],\n","        ]\n","    )\n","    x = tf.pad(x, paddings)\n","    diff = tf.not_equal(x[:-1], x[1:])\n","    adjacent_indices = tf.where(diff)[:, 0]\n","    x = tf.gather(x, adjacent_indices)\n","    mask = x != Constants.LABEL_PAD\n","    x = tf.boolean_mask(x, mask, axis=0)\n","    return x\n","\n","\n","# A utility function to decode the output of the network\n","def decode_batch_predictions(pred):\n","    output_text = []\n","    for result in pred:\n","        result = \"\".join(num_to_char_fn(decode_phrase(result).numpy()))\n","        output_text.append(result)\n","    return output_text\n","\n","\n","\n","\n","def code_to_label(label_code):\n","    label = [Constants.inv_dict[x] for x in label_code if Constants.inv_dict[x] != \"P\"]\n","    label = \"\".join(label)\n","    return label\n","\n","\n","def convert_to_strings(batch_label_code):\n","    output = []\n","    for label_code in batch_label_code:\n","        output.append(code_to_label(label_code))\n","    return output\n","\n","\n","def global_metric(val_ds, model):\n","    global_N, global_D = 0, 0\n","    count = 0\n","    metric = LevDistanceMetric()\n","    for batch in val_ds:\n","        count += 1\n","        print(count)\n","        feature, label = batch\n","        logits = model(feature)\n","        _, _, D = batch_edit_distance(label, logits)\n","        metric.update_state(label, logits)\n","\n","    result = metric.result().numpy()\n","\n","    return result\n","\n","\n","def sparse_from_dense_ignore_value(dense_tensor):\n","    mask = tf.not_equal(dense_tensor, Constants.LABEL_PAD)\n","    indices = tf.where(mask)\n","    values = tf.boolean_mask(dense_tensor, mask)\n","\n","    return tf.SparseTensor(indices, values, tf.shape(dense_tensor, out_type=tf.int64))\n","\n","\n","def batch_edit_distance(y_true, y_logits):\n","    blank = Constants.LABEL_PAD\n","    #y_true=tf.ensure_shape(y_true,(128,Constants.MAX_STRING_LEN))\n","    #y_logits=tf.ensure_shape(y_logits,(128,128,60))\n","    #tf.print(\"edit distance true shape\",tf.shape(y_true))\n","    #tf.print(\"edit distance logits shape\",tf.shape(y_logits))\n","\n","    B = tf.shape(y_logits)[0]\n","    seq_length = tf.shape(y_logits)[1]\n","    to_decode = tf.transpose(y_logits, perm=[1, 0, 2])\n","    sequence_length = tf.fill(dims=[B], value=seq_length)\n","    hypothesis = tf.nn.ctc_greedy_decoder(\n","        tf.cast(to_decode, tf.float32), sequence_length, blank_index=blank\n","    )[0][\n","        0\n","    ]  # full is [B,...]\n","    truth = sparse_from_dense_ignore_value(y_true)  # full is [B,...]\n","    truth = tf.cast(truth, tf.int64)\n","    edit_dist = tf.edit_distance(hypothesis, truth, normalize=False)\n","\n","    non_ignore_mask = tf.not_equal(y_true, blank)\n","    N = tf.reduce_sum(tf.cast(non_ignore_mask, tf.float32))\n","    D = tf.reduce_sum(edit_dist)\n","    result = (N - D) / N\n","    result = tf.clip_by_value(result, 0.0, 1.0)\n","    return result, N, D\n","\n","\n","class LevDistanceMetric(tf.keras.metrics.Metric):\n","    def __init__(self, name=\"Lev\", **kwargs):\n","        super().__init__(name=name, **kwargs)\n","        self.distance = self.add_weight(name=\"dist\", initializer=\"zeros\")\n","        self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n","\n","    def update_state(self, y_true, y_logits, sample_weight=None):\n","        # if using with keras compile, make sure the model outputs logits, not softmax probabilities\n","        _, N, D = batch_edit_distance(y_true, y_logits)\n","        self.distance.assign_add(D)\n","        self.count.assign_add(N)\n","\n","    def result(self):\n","        result = (self.count - self.distance) / self.count\n","        result = tf.clip_by_value(result, 0.0, 1.0)\n","        return result\n","\n","    def reset_state(self):\n","        self.count.assign(0.0)\n","        self.distance.assign(0.0)\n","\n","\n","\n","class SWA(tf.keras.callbacks.Callback):\n","    # Stochastic Weight Averaging\n","    def __init__(\n","        self,\n","        save_name,\n","        swa_epochs=[],\n","        strategy=None,\n","        train_ds=None,\n","        valid_ds=None,\n","        train_steps=1000,\n","    ):\n","        super().__init__()\n","        self.swa_epochs = swa_epochs\n","        self.swa_weights = None\n","        self.save_name = save_name\n","        self.train_ds = train_ds\n","        self.valid_ds = valid_ds\n","        self.train_steps = train_steps\n","        self.strategy = strategy\n","\n","    @tf.function\n","    def train_step(self, iterator):\n","        \"\"\"The step function for one training step.\"\"\"\n","\n","        def step_fn(inputs):\n","            \"\"\"The computation to run on each device.\"\"\"\n","            x, y = inputs\n","            _ = self.model(x, training=True)\n","\n","        for x in iterator:\n","            self.strategy.run(step_fn, args=(x,))\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        if epoch in self.swa_epochs:\n","            self.model.save_weights(f\"{self.save_name}-epoch-{epoch}.h5\")\n","            if self.swa_weights is None:\n","                self.swa_weights = self.model.get_weights()\n","            else:\n","                w = self.model.get_weights()\n","                for i in range(len(self.swa_weights)):\n","                    self.swa_weights[i] += w[i]\n","\n","    def on_train_end(self, logs=None):\n","        if len(self.swa_epochs):\n","            print(\"applying SWA...\")\n","            for i in range(len(self.swa_weights)):\n","                self.swa_weights[i] = self.swa_weights[i] / len(self.swa_epochs)\n","            self.model.set_weights(self.swa_weights)\n","            if self.train_ds is not None:  # for the re-calculation of running mean and var\n","                self.train_step(self.train_ds.take(self.train_steps))\n","            print(f\"save SWA weights to {self.save_name}-SWA.h5\")\n","            self.model.save_weights(f\"{self.save_name}-SWA.h5\")\n","            if self.valid_ds is not None:\n","                print(\"evaluate swa\")\n","                self.model.evaluate(self.valid_ds)\n","\n","\n","class AWP(tf.keras.Model):\n","    # Adversarial Weight Perturbation\n","    def __init__(self, *args, delta=0.1, eps=1e-4, start_step=0, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.delta = delta\n","        self.eps = eps\n","        self.start_step = start_step\n","\n","    def train_step_awp(self, data):\n","        # Unpack the data. Its structure depends on your model and\n","        # on what you pass to `fit()`.\n","        x, y = data\n","\n","        with tf.GradientTape() as tape:\n","            y_pred = self(x, training=True)\n","            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n","        params = self.trainable_variables\n","        params_gradients = tape.gradient(loss, self.trainable_variables)\n","        for i in range(len(params_gradients)):\n","            grad = tf.zeros_like(params[i]) + params_gradients[i]\n","            delta = tf.math.divide_no_nan(\n","                self.delta * grad, tf.math.sqrt(tf.reduce_sum(grad**2)) + self.eps\n","            )\n","            self.trainable_variables[i].assign_add(delta)\n","        with tf.GradientTape() as tape2:\n","            y_pred = self(x, training=True)\n","            new_loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n","            if hasattr(self.optimizer, \"get_scaled_loss\"):\n","                new_loss = self.optimizer.get_scaled_loss(new_loss)\n","\n","        gradients = tape2.gradient(new_loss, self.trainable_variables)\n","        if hasattr(self.optimizer, \"get_unscaled_gradients\"):\n","            gradients = self.optimizer.get_unscaled_gradients(gradients)\n","        for i in range(len(params_gradients)):\n","            grad = tf.zeros_like(params[i]) + params_gradients[i]\n","            delta = tf.math.divide_no_nan(\n","                self.delta * grad, tf.math.sqrt(tf.reduce_sum(grad**2)) + self.eps\n","            )\n","            self.trainable_variables[i].assign_sub(delta)\n","        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n","        # self_loss.update_state(loss)\n","        self.compiled_metrics.update_state(y, y_pred)\n","        return {m.name: m.result() for m in self.metrics}\n","\n","    def train_step(self, data):\n","        return tf.cond(\n","            self._train_counter < self.start_step,\n","            lambda: super(AWP, self).train_step(data),\n","            lambda: self.train_step_awp(data),\n","        )\n"]},{"cell_type":"markdown","metadata":{"id":"vR98ska2k6tq"},"source":["# Confromer"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"A73Z3NEmk9O7"},"outputs":[],"source":["\n","class GLU(tf.keras.layers.Layer):\n","    def __init__(self, dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.dim = dim\n","        self.supports_masking = True\n","\n","    def call(self, x):\n","        out, gate = tf.split(x, num_or_size_splits=2, axis=self.dim)\n","        return out * tf.nn.sigmoid(gate)\n","\n","\n","class FeedForward(tf.keras.layers.Layer):\n","    def __init__(self, dim, mult=4, dropout=0.0, **kwargs):\n","        super().__init__(**kwargs)\n","        self.net = tf.keras.Sequential(\n","            [\n","                tf.keras.layers.Dense(dim * mult, activation=\"swish\"),\n","                tf.keras.layers.Dropout(dropout),\n","                tf.keras.layers.Dense(dim),\n","                tf.keras.layers.Dropout(dropout),\n","            ]\n","        )\n","        self.supports_masking = True\n","\n","    def call(self, x):\n","        outputs = self.net(x)\n","        return outputs\n","\n","class ConformerConvModule(tf.keras.layers.Layer):\n","    def __init__(\n","        self, dim,  expansion_factor=2,strides=1, kernel_size=17, dropout=0.0, **kwargs\n","    ):\n","        super().__init__(**kwargs)\n","\n","        inner_dim = dim * expansion_factor\n","        #padding = \"causal\" if causal else \"same\"\n","\n","        self.ln = tf.keras.layers.LayerNormalization()\n","        self.dense1 = tf.keras.layers.Dense(inner_dim)\n","        self.glu = GLU(2)\n","        self.causal_pad = tf.keras.layers.ZeroPadding1D(( kernel_size - 1, 0))\n","        self.conv1d = tf.keras.layers.DepthwiseConv1D(kernel_size, strides=strides,padding=\"valid\")\n","        self.bn = tf.keras.layers.BatchNormalization()\n","        self.swish = tf.keras.layers.Activation(\"swish\")\n","        self.dense2 = tf.keras.layers.Dense(dim, use_bias=False)\n","        self.do = tf.keras.layers.Dropout(dropout)\n","\n","        self.supports_masking = True\n","\n","    def call(self, inputs, mask=None):\n","\n","        x = self.ln(inputs)\n","        x = self.dense1(x)\n","        x = self.glu(x)\n","        x=self.causal_pad(x)\n","        x = self.conv1d(x)\n","\n","        x = self.bn(x, mask=mask)\n","        x = self.swish(x)\n","        x = self.dense2(x)\n","        x = self.do(x)\n","\n","        return x\n","\n","\n","class MultiHeadRelativeSelfAttention(tf.keras.layers.Layer):\n","    def __init__(self, max_len, dim, dim_head, num_heads, dropout=0.0, **kwargs):\n","        super().__init__(**kwargs)\n","\n","        self.dim = dim\n","        self.dim_head = dim_head\n","        self.num_heads = num_heads\n","        self.max_len = max_len\n","        self.positional_embeddings = self.create_positional_embeddings(max_len, dim)\n","        self.qkv = tf.keras.layers.Dense(units=3 * num_heads * dim_head, use_bias=False, name=\"qkv\")\n","        self.r_head = tf.keras.layers.Dense(units=num_heads * dim_head, use_bias=False, name=\"r\")\n","        self.project = tf.keras.layers.Dense(dim, use_bias=False, name=\"o\")\n","        self.soft= tf.keras.layers.Softmax(axis=-1)\n","        self.supports_masking = True\n","\n","    def positional_embedding(self, pos_seq, inv_freq):\n","        sinusoid_inp = tf.einsum(\"i,j->ij\", pos_seq, inv_freq)\n","        pos_emb = tf.concat([tf.sin(sinusoid_inp), tf.cos(sinusoid_inp)], -1)\n","        return pos_emb[:, None, :]\n","\n","    def rel_shift(self, x):\n","        x_size = tf.shape(x)\n","\n","        x = tf.pad(x, [[0, 0], [0, 0], [0, 0], [1, 0]])\n","        x = tf.reshape(x, [x_size[0], x_size[1], x_size[3] + 1, x_size[2]])\n","        x = tf.slice(x, [0, 0, 1, 0], [-1, -1, -1, -1])\n","        x = tf.reshape(x, x_size)\n","\n","        return x\n","\n","    def create_positional_embeddings(self, max_len, dim):\n","        pos_seq = tf.range(max_len - 1, -1, -1.0)\n","        inv_freq = 1 / (1000 ** (tf.range(0, dim, 2.0) / dim))\n","        pos_emb = self.positional_embedding(pos_seq, inv_freq)\n","        return pos_emb\n","\n","    def call(self, inputs, mask=None):\n","        #assert mask is not None\n","\n","        bsz = tf.shape(inputs)[0]\n","        x = tf.transpose(inputs, (1, 0, 2))  # Change from Batch first to Time first\n","\n","        scale = 1 / (self.dim_head**0.5)\n","        w_heads = self.qkv(x)\n","        r_head_k = self.r_head(self.positional_embeddings)\n","\n","        w_head_q, w_head_k, w_head_v = tf.split(w_heads, 3, -1)\n","        w_head_q = w_head_q[-self.max_len :]\n","\n","        w_head_q = tf.reshape(w_head_q, [self.max_len, bsz, self.num_heads, self.dim_head])\n","        w_head_k = tf.reshape(w_head_k, [self.max_len, bsz, self.num_heads, self.dim_head])\n","        w_head_v = tf.reshape(w_head_v, [self.max_len, bsz, self.num_heads, self.dim_head])\n","\n","        r_head_k = tf.reshape(r_head_k, [self.max_len, self.num_heads, self.dim_head])\n","\n","        AC = tf.einsum(\"ibnd,jbnd->bnij\", w_head_q, w_head_k)  # query attending to key\n","        BD = tf.einsum(\n","            \"ibnd,jnd->bnij\", w_head_q, r_head_k\n","        )  # query attending to positional encoding\n","        BD = self.rel_shift(BD)  # relative shift trick (appendix B of Transformer XL paper)\n","\n","        attn_score = (\n","            AC + BD\n","        ) * scale  # tensor with shape Batch, num_heads,Time (query),Time (key)\n","\n","        if mask is not None:\n","          mask = tf.cast(mask[:, None, None, :], attn_score.dtype)\n","\n","        attn_prob = self.soft(attn_score, mask=mask)\n","\n","        attn_vec = tf.einsum(\"bnij,jbnd->bind\", attn_prob, w_head_v)  # Batch,Time, Heads,D\n","        attn_vec = tf.reshape(attn_vec, [bsz, self.max_len, self.num_heads * self.dim_head])\n","\n","        attn_out = self.project(attn_vec)\n","\n","        x = attn_out + inputs  # residual connection\n","\n","        return x\n","\n","\n","class AttentionBlock(tf.keras.layers.Layer):\n","    def __init__(self, max_len, dim, dim_head, num_heads, dropout=0.0, **kwargs):\n","        super().__init__(**kwargs)\n","        self.ln = tf.keras.layers.LayerNormalization()\n","        self.MHRA = MultiHeadRelativeSelfAttention(max_len, dim, dim_head, num_heads)\n","        self.do = tf.keras.layers.Dropout(dropout)\n","        self.supports_masking = True\n","\n","    def call(self, inputs, mask=None):\n","        x = self.ln(inputs)\n","        x = self.MHRA(x,mask=mask)\n","        x = self.do(x)\n","        return x\n","\n","\n","# Conformer Block\n","\n","\n","class ConformerBlock(tf.keras.layers.Layer):\n","    def __init__(\n","        self,\n","        max_len,\n","        dim,\n","        dim_head=32,\n","        num_heads=6,\n","        ff_mult=1, #4\n","        conv_expansion_factor=1,\n","        conv_kernel_size=17,\n","        strides=1,\n","        dropout=0.0,\n","        **kwargs\n","    ):\n","        super().__init__(**kwargs)\n","        self.ff1 = FeedForward(dim=dim, mult=ff_mult, dropout=dropout)\n","        self.ff2 = FeedForward(dim=dim, mult=ff_mult, dropout=dropout)\n","        self.attn = AttentionBlock(\n","            max_len, dim=dim, dim_head=dim_head, num_heads=num_heads, dropout=dropout\n","        )\n","        self.conv = ConformerConvModule(\n","            dim=dim,\n","            kernel_size=conv_kernel_size,\n","            strides=strides,\n","            expansion_factor=conv_expansion_factor,\n","            dropout=dropout,\n","        )\n","        self.ln = tf.keras.layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, mask=None):\n","        #assert mask is not None\n","        x = inputs + 0.5 * self.ff1(inputs)\n","        x = x + self.attn(x,mask=mask)\n","        x = x + self.conv(x,mask=mask)\n","        x = x + 0.5 * self.ff2(x)\n","        x = self.ln(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["# hard swish"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["\n","def HardSwish(x):\n","    return tf.keras.layers.Multiply()([tf.keras.layers.Activation(\"hard_sigmoid\")(x), x])\n","from tensorflow.keras.saving import get_custom_objects\n","\n","### Note! You cannot use random python functions, activation function gets as an input tensorflow tensors and should return tensors. There are a lot of helper functions in keras backend.\n","get_custom_objects().update({'hswish': tf.keras.layers.Activation(HardSwish)})\n"]},{"cell_type":"markdown","metadata":{},"source":["# Light MSA"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["\n","class OpSequential(tf.keras.layers.Layer):\n","    def __init__(self, op_list,**kwargs):\n","        super(OpSequential, self).__init__(**kwargs)\n","        valid_op_list = []\n","        for op in op_list:\n","            if op is not None:\n","                valid_op_list.append(op)\n","        self.op_list = valid_op_list\n","\n","    def call(self, x):\n","        for op in self.op_list:\n","            x = op(x)\n","        return x\n","\n","def val2list(x: list or tuple or any, repeat_time=1) -> list:\n","    if isinstance(x, (list, tuple)):\n","        return list(x)\n","    return [x for _ in range(repeat_time)]\n","\n","def val2tuple(x: list or tuple or any, min_len: int = 1, idx_repeat: int = -1) -> tuple:\n","    x = val2list(x)\n","\n","    # repeat elements if necessary\n","    if len(x) > 0:\n","        x[idx_repeat:idx_repeat] = [x[idx_repeat] for _ in range(min_len - len(x))]\n","\n","    return tuple(x)\n","\n","\n","class ConvLayer(tf.keras.layers.Layer):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        kernel_size=9, #3\n","        stride=1,\n","        dilation=1,\n","        groups=1,\n","        use_bias=False,\n","        dropout=0,\n","        norm=\"bn\",\n","        act_func=\"relu\",\n","        **kwargs,\n","    ):\n","        super(ConvLayer, self).__init__(**kwargs)\n","\n","\n","        self.dropout = tf.keras.layers.Dropout(dropout) if dropout > 0 else None\n","        self.conv = tf.keras.layers.Conv1D(\n","            out_channels,\n","            kernel_size=kernel_size,\n","            strides=stride,\n","            padding=\"same\",\n","            dilation_rate=dilation,\n","            groups=groups,\n","            use_bias=use_bias,\n","        )\n","        if norm==\"bn\":\n","            self.norm = tf.keras.layers.BatchNormalization()\n","        else:\n","            self.norm=None\n","        if act_func:\n","            self.act = tf.keras.layers.Activation(act_func)\n","        else:\n","            self.act=None\n","\n","    def call(self, x):\n","        if self.dropout is not None:\n","            x = self.dropout(x)\n","        x = self.conv(x)\n","        if self.norm:\n","            x = self.norm(x)\n","        if self.act:\n","            x = self.act(x)\n","        return x\n","\n","\n","class UpSampleLayer(tf.keras.layers.Layer):\n","    def __init__(\n","        self,\n","        factor=None,\n","        **kwargs\n","    ):\n","        super(UpSampleLayer, self).__init__(**kwargs)\n","        if factor:\n","            self.up=tf.keras.layers.UpSampling1D(factor)\n","        else:\n","            self.up=tf.keras.layers.Identity()\n","\n","    def call(self, x):\n","        return self.up(x)\n","\n","\n","\n","\n","\n","class DSConv(tf.keras.layers.Layer):\n","    def __init__(\n","        self,\n","        in_channels,\n","        out_channels,\n","        kernel_size=9, #3\n","        stride=1,\n","        use_bias=False,\n","        norm=\"bn\",\n","        act_func=(\"relu6\", None),\n","        point_groups=1,\n","        **kwargs\n","    ):\n","        super(DSConv, self).__init__(**kwargs)\n","\n","        use_bias = val2tuple(use_bias, 2)\n","        norm = val2tuple(norm, 2)\n","        act_func = val2tuple(act_func, 2)\n","\n","        self.depth_conv = ConvLayer(\n","            in_channels,\n","            in_channels,\n","            kernel_size,\n","            stride,\n","            groups=in_channels,\n","            norm=norm[0],\n","            act_func=act_func[0],\n","            use_bias=use_bias[0],\n","        )\n","        self.point_conv = ConvLayer(\n","            in_channels,\n","            out_channels,\n","            1,\n","            groups=point_groups,\n","            norm=norm[1],\n","            act_func=act_func[1],\n","            use_bias=use_bias[1],\n","        )\n","\n","\n","\n","class ResidualBlock(tf.keras.layers.Layer):\n","    def __init__(\n","        self,\n","        main,\n","        shortcut,\n","        post_act=None,\n","        pre_norm=None,\n","        **kwargs\n","    ):\n","        super().__init__(**kwargs)\n","\n","        self.pre_norm = pre_norm\n","        self.main = main\n","        self.shortcut = shortcut\n","        self.post_act = tf.keras.layers.Activation(post_act)\n","\n","    def forward_main(self, x):\n","        if self.pre_norm is None:\n","            return self.main(x)\n","        else:\n","            return self.main(self.pre_norm(x))\n","\n","    def call(self, x):\n","        if self.main is None:\n","            res = x\n","        elif self.shortcut is None:\n","            res = self.forward_main(x)\n","        else:\n","            res = self.forward_main(x) + self.shortcut(x)\n","            if self.post_act:\n","                res = self.post_act(res)\n","        return res\n","\n","\n","\n","class MBConv(tf.keras.layers.Layer):\n","    def __init__(\n","        self,\n","        in_channels,\n","        out_channels,\n","        kernel_size=9, #3\n","        stride=1,\n","        mid_channels=None,\n","        expand_ratio=6,\n","        use_bias=(False,False,False),\n","        norm=\"bn\",\n","        act_func=(\"relu6\", \"relu6\", None),\n","        **kwargs\n","    ):\n","        super().__init__(**kwargs)\n","\n","\n","        use_bias = val2tuple(use_bias, 3)\n","        norm = val2tuple(norm, 3)\n","        act_func = val2tuple(act_func, 3)\n","\n","        mid_channels = mid_channels or round(in_channels * expand_ratio)\n","\n","        self.inverted_conv = ConvLayer(\n","            in_channels,\n","            mid_channels,\n","            1,\n","            stride=1,\n","            norm=norm[0],\n","            act_func=act_func[0],\n","            use_bias=use_bias[0],\n","        )\n","\n","        self.depth_conv = ConvLayer(\n","            mid_channels,\n","            mid_channels,\n","            kernel_size,\n","            stride=stride,\n","            groups=mid_channels,\n","            norm=norm[1],\n","            act_func=act_func[1],\n","            use_bias=use_bias[1],\n","        )\n","        self.point_conv = ConvLayer(\n","            mid_channels,\n","            out_channels,\n","            1,\n","            norm=norm[2],\n","            act_func=act_func[2],\n","            use_bias=use_bias[2],\n","        )\n","\n","\n","\n","    def call(self, x):\n","        x = self.inverted_conv(x)\n","        x = self.depth_conv(x)\n","        x = self.point_conv(x)\n","        return x\n","    \n","\n","    \n","class LiteMSA(tf.keras.layers.Layer):\n","    r\"\"\"Lightweight multi-scale attention\"\"\"\n","\n","    def __init__(\n","        self,\n","        in_channels,\n","        out_channels, \n","        heads =None,\n","        heads_ratio = 1.0,\n","        dim=8,\n","        use_bias=(False,False),\n","        norm=(None, \"bn\"),\n","        act_func=(None,None),\n","        kernel_func=\"relu\",\n","        scales = (17,),\n","        **kwargs\n","    ):\n","        super().__init__(**kwargs)\n","        heads = heads or int(in_channels // dim * heads_ratio)\n","\n","        total_dim = heads * dim\n","\n","        self.dim = dim\n","\n","        self.qkv = ConvLayer(\n","            in_channels,\n","            3 * total_dim,\n","            1,\n","            use_bias=use_bias[0],\n","            norm=norm[0],\n","            act_func=act_func[0],\n","        )\n","        self.aggreg=[]\n","        for scale in scales:\n","            \"\"\"\n","            reg=tf.keras.Sequential(\n","                        [\n","                            tf.keras.layers.DepthwiseConv1D(\n","                            scale,\n","                            padding=\"same\",\n","                            use_bias=use_bias[0],\n","                            ),\n","                            tf.keras.layers.Conv1D(3 * total_dim, 1, groups=3 * heads, use_bias=use_bias[0])\n","                        ]\n","                    )\n","            \"\"\"\n","            reg=DSConv(3*total_dim,3*total_dim,kernel_size=scale,use_bias=use_bias[0],norm=None,act_func=None,point_groups=3*heads)\n","            self.aggreg.append(reg)\n","\n","        self.kernel_func = tf.keras.layers.Activation(kernel_func)\n","\n","        self.proj = ConvLayer(\n","            total_dim * (1 + len(scales)),\n","            out_channels,\n","            1,\n","            use_bias=use_bias[1],\n","            norm=norm[1],\n","            act_func=act_func[1],\n","        )    \n","        \n","        self.concat=tf.keras.layers.Concatenate()\n","\n","    def call(self, x):\n","        B, H,_ = tf.shape(x)\n","        \n","        # generate multi-scale q, k, v\n","        qkv = self.qkv(x)\n","     \n","        multi_scale_qkv = [qkv]\n","        for op in self.aggreg:\n","            multi_scale_qkv.append(op(qkv))\n","        multi_scale_qkv = self.concat(multi_scale_qkv)\n","\n","        multi_scale_qkv = tf.reshape(multi_scale_qkv,(B,H,-1,3 * self.dim)) # (B,H,heads,3*dim)\n","        multi_scale_qkv = tf.transpose(multi_scale_qkv, (0,2,1,3)) # (B,heads,H,3*dim) \n","        q, k, v = (\n","            multi_scale_qkv[..., 0 : self.dim],\n","            multi_scale_qkv[..., self.dim : 2 * self.dim],\n","            multi_scale_qkv[..., 2 * self.dim :],\n","        )\n","\n","        # lightweight global attention\n","        q = self.kernel_func(q)\n","        k = self.kernel_func(k) # (B,heads,H,dim)\n","\n","        trans_k = tf.transpose(k,(0,1,3,2)) # (B,heads,dim,H)\n","\n","        v=tf.pad(v,paddings=[[0,0],[0,0],[0,0],[0,1]],constant_values=1) # (B,heads,H,dim+1)\n","        kv = tf.linalg.matmul(trans_k, v) # (B,heads,dim,dim+1)\n","        out = tf.linalg.matmul(q, kv) # (B,heads,H,dim+1)\n","        out = out[..., :-1] / (out[..., -1:] + 1e-15) # (B,heads,H,dim)\n","\n","        # final projecttion\n","        out = tf.transpose(out, (0,2,1,3)) # (B,H,heads,dim)\n","        out = tf.reshape(out, (B, H,-1))\n","        out = self.proj(out)\n","\n","        return out\n","\n","    \n","class EfficientViTBlock(tf.keras.layers.Layer):\n","    def __init__(\n","        self,\n","        in_channels,\n","        heads_ratio = 1.0,\n","        dim=32,\n","        expand_ratio = 4,\n","        norm=\"bn\",\n","        act_func=\"hswish\",\n","        **kwargs\n","    ):\n","        super().__init__(**kwargs)\n","        self.context_module = ResidualBlock(\n","            LiteMSA(\n","                in_channels=in_channels,\n","                out_channels=in_channels,\n","                heads_ratio=heads_ratio,\n","                dim=dim,\n","                norm=(None, norm),\n","            ),\n","            tf.keras.layers.Identity(),\n","        )\n","        local_module = MBConv(\n","            in_channels=in_channels,\n","            out_channels=in_channels,\n","            expand_ratio=expand_ratio,\n","            use_bias=(True, True, False),\n","            norm=(None, None, norm),\n","            act_func=(act_func, act_func, None),\n","        )\n","        self.local_module = ResidualBlock(local_module, tf.keras.layers.Identity())\n","\n","    def call(self, x):\n","        #x = self.context_module(x)\n","        x = self.local_module(x)\n","        return x\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Backbone"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["\n","\n","class EfficientViTBackbone(tf.keras.layers.Layer):\n","    def __init__(\n","        self,\n","        width_list: list[int],\n","        depth_list: list[int],\n","        in_channels=3,\n","        dim=32,\n","        expand_ratio=4,\n","        norm=\"bn\",\n","        act_func=\"hswish\",\n","        **kwargs\n","    ) -> None:\n","        super().__init__(**kwargs)\n","\n","        self.width_list = []\n","        # input stem\n","        self.input_stem = [\n","            ConvLayer(\n","                in_channels=3,\n","                out_channels=width_list[0],\n","                stride=1, #2\n","                norm=norm,\n","                act_func=act_func,\n","            )\n","        ]\n","        for _ in range(depth_list[0]):\n","            block = self.build_local_block(\n","                in_channels=width_list[0],\n","                out_channels=width_list[0],\n","                stride=1,\n","                expand_ratio=1,\n","                norm=norm,\n","                act_func=act_func,\n","            )\n","            self.input_stem.append(ResidualBlock(block, tf.keras.layers.Identity()))\n","        in_channels = width_list[0]\n","        self.input_stem = OpSequential(self.input_stem)\n","        self.width_list.append(in_channels)\n","\n","        # stages\n","        self.stages = []\n","        for w, d in zip(width_list[1:3], depth_list[1:3]):\n","            stage = []\n","            for i in range(d):\n","                stride = 2 if i == 0 else 1\n","                block = self.build_local_block(\n","                    in_channels=in_channels,\n","                    out_channels=w,\n","                    stride=stride,\n","                    expand_ratio=expand_ratio,\n","                    norm=norm,\n","                    act_func=act_func,\n","                )\n","                block = ResidualBlock(block, tf.keras.layers.Identity() if stride == 1 else None)\n","                stage.append(block)\n","                in_channels = w\n","            self.stages.append(OpSequential(stage))\n","            self.width_list.append(in_channels)\n","\n","        for w, d in zip(width_list[3:], depth_list[3:]):\n","            stage = []\n","            block = self.build_local_block(\n","                in_channels=in_channels,\n","                out_channels=w,\n","                stride=2,\n","                expand_ratio=expand_ratio,\n","                norm=norm,\n","                act_func=act_func,\n","                fewer_norm=True,\n","            )\n","            stage.append(ResidualBlock(block, None))\n","            in_channels = w\n","\n","            for _ in range(d):\n","                stage.append(\n","                    EfficientViTBlock(\n","                        in_channels=in_channels,\n","                        dim=dim,\n","                        expand_ratio=expand_ratio,\n","                        norm=norm,\n","                        act_func=act_func,\n","                    )\n","                )\n","            self.stages.append(OpSequential(stage))\n","            self.width_list.append(in_channels)\n","\n","\n","    @staticmethod\n","    def build_local_block(\n","        in_channels,\n","        out_channels,\n","        stride,\n","        expand_ratio,\n","        norm,\n","        act_func,\n","        fewer_norm=False,\n","    ):\n","        if expand_ratio == 1:\n","            block = DSConv(\n","                in_channels=in_channels,\n","                out_channels=out_channels,\n","                stride=stride,\n","                use_bias=(True, False) if fewer_norm else False,\n","                norm=(None, norm) if fewer_norm else norm,\n","                act_func=(act_func, None),\n","            )\n","            \n","        else:\n","            block = MBConv(\n","                in_channels=in_channels,\n","                out_channels=out_channels,\n","                stride=stride,\n","                expand_ratio=expand_ratio,\n","                use_bias=(True, True, False) if fewer_norm else False,\n","                norm=(None, None, norm) if fewer_norm else norm,\n","                act_func=(act_func, act_func, None),\n","            )\n","        return block\n","\n","    def call(self, x):\n","        output_dict = {\"input\": x}\n","        output_dict[\"stage0\"] = x = self.input_stem(x)\n","        for stage_id, stage in enumerate(self.stages, 1):\n","            output_dict[\"stage%d\" % stage_id] = x = stage(x)\n","        output_dict[\"stage_final\"] = x\n","        return output_dict\n","\n","\n","from inspect import signature\n","def build_kwargs_from_config(config: dict, target_func: callable) -> dict[str, any]:\n","    valid_keys = list(signature(target_func).parameters)\n","    kwargs = {}\n","    for key in config:\n","        if key in valid_keys:\n","            kwargs[key] = config[key]\n","    return kwargs\n","\n","def efficientvit_backbone_a0(**kwargs) -> EfficientViTBackbone:\n","    backbone = EfficientViTBackbone(\n","        width_list=[8, 16, 32, 64, 128],\n","        depth_list=[1, 2, 2, 2, 2],\n","        dim=16,\n","        **build_kwargs_from_config(kwargs, EfficientViTBackbone),\n","    )\n","    return backbone\n","\n","\n","def efficientvit_backbone_b0(**kwargs) -> EfficientViTBackbone:\n","    backbone = EfficientViTBackbone(\n","        width_list=[8, 16, 32, 64, 128],\n","        depth_list=[1, 2, 2, 2, 2],\n","        dim=16,\n","        **build_kwargs_from_config(kwargs, EfficientViTBackbone),\n","    )\n","    return backbone\n","\n","\n","def efficientvit_backbone_b1(**kwargs) -> EfficientViTBackbone:\n","    backbone = EfficientViTBackbone(\n","        width_list=[16, 32, 64, 128, 256],\n","        depth_list=[1, 2, 3, 3, 4],\n","        dim=16,\n","        **build_kwargs_from_config(kwargs, EfficientViTBackbone),\n","    )\n","    return backbone\n","\n","\n","def efficientvit_backbone_b2(**kwargs) -> EfficientViTBackbone:\n","    backbone = EfficientViTBackbone(\n","        width_list=[24, 48, 96, 192, 384],\n","        depth_list=[1, 3, 4, 4, 6],\n","        dim=32,\n","        **build_kwargs_from_config(kwargs, EfficientViTBackbone),\n","    )\n","    return backbone\n","\n","\n","def efficientvit_backbone_b3(**kwargs) -> EfficientViTBackbone:\n","    backbone = EfficientViTBackbone(\n","        width_list=[32, 64, 128, 256, 512],\n","        depth_list=[1, 4, 6, 6, 9],\n","        dim=32,\n","        **build_kwargs_from_config(kwargs, EfficientViTBackbone),\n","    )\n","    return backbone"]},{"cell_type":"markdown","metadata":{},"source":["# Seg"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["\n","def list_sum(x: list) -> any:\n","    return x[0] if len(x) == 1 else x[0] + list_sum(x[1:])\n","\n","class DAGBlock(tf.keras.layers.Layer):\n","    def __init__(\n","        self,\n","        inputs, # dict\n","        merge,\n","        post_input,\n","        middle,\n","        outputs, #dict,\n","        **kwargs\n","    ):\n","        super(DAGBlock, self).__init__(**kwargs)\n","\n","        self.input_keys = list(inputs.keys())\n","        self.input_ops = list(inputs.values())\n","        self.merge = merge\n","        self.post_input = post_input\n","\n","        self.middle = middle\n","\n","        self.output_keys = list(outputs.keys())\n","        self.output_ops = list(outputs.values())\n","        self.concat=tf.keras.layers.Concatenate()\n","\n","    def call(self, feature_dict):\n","        feat = [op(feature_dict[key]) for key, op in zip(self.input_keys, self.input_ops)]\n","        if self.merge == \"add\":\n","            feat = list_sum(feat)\n","        elif self.merge == \"cat\":\n","            feat = self.concat(feat)\n","        else:\n","            raise NotImplementedError\n","        if self.post_input is not None:\n","            feat = self.post_input(feat)\n","        feat = self.middle(feat)\n","        for key, op in zip(self.output_keys, self.output_ops):\n","            feature_dict[key] = op(feat)\n","        return feature_dict\n","\n","\n","\n","\n","class SegHead(DAGBlock):\n","    def __init__(\n","        self,\n","        fid_list: list[str],\n","        in_channel_list: list[int],\n","        stride_list: list[int],\n","        head_stride: int,\n","        head_width: int,\n","        head_depth: int,\n","        expand_ratio: float,\n","        final_expand: float or None,\n","        n_classes: int,\n","        dropout=0,\n","        norm=\"bn\",\n","        act_func=\"hswish\",\n","    ):\n","        inputs = {}\n","        for fid, in_channel, stride in zip(fid_list, in_channel_list, stride_list):\n","            factor = stride // head_stride\n","            if factor == 1:\n","                inputs[fid] = ConvLayer(in_channel, head_width, 1, norm=norm, act_func=None)\n","            else:\n","                inputs[fid] = OpSequential(\n","                    [\n","                        ConvLayer(in_channel, head_width, 1, norm=norm, act_func=None),\n","                        UpSampleLayer(factor=factor),\n","                    ]\n","                )\n","\n","        middle = []\n","        for _ in range(head_depth):\n","            block = MBConv(\n","                head_width,\n","                head_width,\n","                expand_ratio=expand_ratio,\n","                norm=norm,\n","                act_func=(act_func, act_func, None),\n","            )\n","            middle.append(ResidualBlock(block, tf.keras.layers.Identity()))\n","        middle = OpSequential(middle)\n","\n","        outputs = {\n","            \"segout\": OpSequential(\n","                [\n","                    None\n","                    if final_expand is None\n","                    else ConvLayer(head_width, head_width * final_expand, 1, norm=norm, act_func=act_func),\n","                    ConvLayer(\n","                        head_width * (final_expand or 1),\n","                        n_classes,\n","                        1,\n","                        use_bias=True,\n","                        dropout=dropout,\n","                        norm=None,\n","                        act_func=None,\n","                    ),\n","                ]\n","            )\n","        }\n","\n","        super(SegHead, self).__init__(inputs, \"add\", None, middle=middle, outputs=outputs)\n","\n","\n","class EfficientViTSeg(tf.keras.layers.Layer):\n","    def __init__(self, backbone: EfficientViTBackbone, head: SegHead,**kwargs) -> None:\n","        super().__init__(**kwargs)\n","        self.backbone = backbone\n","        self.head = head\n","\n","    def call(self, x):\n","        feed_dict = self.backbone(x)\n","        feed_dict = self.head(feed_dict)\n","\n","        return feed_dict[\"segout\"]\n","\n","\n","def efficientvit_seg_a0( **kwargs):\n","\n","    backbone = efficientvit_backbone_a0(**kwargs)\n","\n","    input_width=384\n","    head_width=96\n","    head_stride=input_width//head_width\n","    head = SegHead(\n","        fid_list=[\"stage4\", \"stage3\", \"stage2\"],\n","        in_channel_list=[head_width, head_width//2, head_width//4],\n","        stride_list=[4*head_stride, 2*head_stride, head_stride],\n","        head_stride=head_stride,\n","        head_width=32,\n","        head_depth=1,\n","        expand_ratio=4,\n","        final_expand=4,\n","        n_classes=60,\n","        **build_kwargs_from_config(kwargs, SegHead),\n","    )\n","    model = EfficientViTSeg(backbone, head)\n","    return model\n","\n","\n","\n","def efficientvit_seg_b0( **kwargs):\n","\n","    backbone = efficientvit_backbone_b0(**kwargs)\n","\n","    head = SegHead(\n","        fid_list=[\"stage4\", \"stage3\", \"stage2\"],\n","        in_channel_list=[128, 64, 32],\n","        stride_list=[32, 16, 8],\n","        head_stride=8,\n","        head_width=32,\n","        head_depth=1,\n","        expand_ratio=4,\n","        final_expand=4,\n","        n_classes=60,\n","        **build_kwargs_from_config(kwargs, SegHead),\n","    )\n","    model = EfficientViTSeg(backbone, head)\n","    return model\n","\n","\n","def efficientvit_seg_b1(**kwargs) -> EfficientViTSeg:\n","\n","    backbone = efficientvit_backbone_b1(**kwargs)\n","\n","    head = SegHead(\n","        fid_list=[\"stage4\", \"stage3\", \"stage2\"],\n","        in_channel_list=[256, 128, 64],\n","        stride_list=[32, 16, 8],\n","        head_stride=8,\n","        head_width=64,\n","        head_depth=3,\n","        expand_ratio=4,\n","        final_expand=4,\n","        n_classes=60,\n","        **build_kwargs_from_config(kwargs, SegHead),\n","    )\n","\n","    model = EfficientViTSeg(backbone, head)\n","    return model\n","\n","\n","def efficientvit_seg_b2(**kwargs) -> EfficientViTSeg:\n","\n","    backbone = efficientvit_backbone_b2(**kwargs)\n","\n","   \n","    head = SegHead(\n","        fid_list=[\"stage4\", \"stage3\", \"stage2\"],\n","        in_channel_list=[384, 192, 96],\n","        stride_list=[32, 16, 8],\n","        head_stride=8,\n","        head_width=96,\n","        head_depth=3,\n","        expand_ratio=4,\n","        final_expand=4,\n","        n_classes=19,\n","        **build_kwargs_from_config(kwargs, SegHead),\n","    )\n","    model = EfficientViTSeg(backbone, head)\n","    return model\n","\n","\n","def efficientvit_seg_b3(**kwargs) -> EfficientViTSeg:\n","\n","    backbone = efficientvit_backbone_b3(**kwargs)\n","    head = SegHead(\n","        fid_list=[\"stage4\", \"stage3\", \"stage2\"],\n","        in_channel_list=[512, 256, 128],\n","        stride_list=[32, 16, 8],\n","        head_stride=8,\n","        head_width=128,\n","        head_depth=3,\n","        expand_ratio=4,\n","        final_expand=4,\n","        n_classes=19,\n","        **build_kwargs_from_config(kwargs, SegHead),\n","    )\n","    model = EfficientViTSeg(backbone, head)\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"YQAPz56nYi15"},"source":["# Model"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"wnoZyLAcYi15"},"outputs":[],"source":["class Residual(tf.keras.layers.Layer):\n","\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        self.supports_masking=True\n","\n","    def call(self, inputs,mask=None):\n","      return inputs[0]+inputs[1]\n","    def compute_mask(self,x,mask=None):\n","      if mask is not None:\n","        return mask[0]\n","      else:\n","        return None\n","\n","\n","\n","class Unmask(tf.keras.layers.Layer):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","    def call(self, x,mask=None):\n","        xc=tf.identity(x)\n","        return xc\n","\n","\n","\n","class MaskLoss(tf.keras.layers.Layer):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        self.pad=tf.constant([-1e6]*59+[1.],dtype=tf.float32)\n","\n","\n","    def call(self, x,mask=None):\n","        if mask is None:\n","          return x\n","\n","        M=tf.cast(mask,x.dtype)\n","        x = x * tf.expand_dims(M, axis=-1) + tf.expand_dims(tf.cast(self.pad,x.dtype), axis=0) * tf.expand_dims(1-M, axis=-1)\n","\n","        return x\n","\n","\n","\n","\n","class CTCLoss(tf.keras.losses.Loss):\n","    def __init__(self, pad_token_idx):\n","        self.pad_token_idx = pad_token_idx\n","        super().__init__()\n","\n","    def call(self, labels, logits):\n","\n","        label_length = tf.reduce_sum(tf.cast(labels != self.pad_token_idx, tf.int32), axis=-1)\n","        logit_length = tf.ones(tf.shape(logits)[0], dtype=tf.int32) * tf.shape(logits)[1]\n","\n","        ctc_loss = tf.nn.ctc_loss(\n","            labels=labels,\n","            logits=logits,\n","            label_length=label_length,\n","            logit_length=logit_length,\n","            blank_index=self.pad_token_idx,\n","            logits_time_major=False,\n","        )\n","\n","        return ctc_loss\n","\n","\n","class ECA(tf.keras.layers.Layer):\n","    # Efficient Channel Attention\n","    def __init__(self, kernel_size=5, **kwargs):\n","        super().__init__(**kwargs)\n","        self.supports_masking = True\n","        self.kernel_size = kernel_size\n","        self.conv = tf.keras.layers.Conv1D(\n","            1, kernel_size=kernel_size, strides=1, padding=\"same\", use_bias=False\n","        )\n","\n","    def call(self, inputs, mask=None):\n","        #assert mask is not None\n","        nn = tf.keras.layers.GlobalAveragePooling1D()(inputs, mask=mask)\n","        nn = tf.expand_dims(nn, -1)\n","        nn = self.conv(nn)\n","        nn = tf.squeeze(nn, -1)\n","        nn = tf.nn.sigmoid(nn)\n","        nn = nn[:, None, :]\n","        return inputs * nn\n","\n","\n","class LateDropout(tf.keras.layers.Layer):\n","    def __init__(self, rate, noise_shape=None, start_step=0, **kwargs):\n","        super().__init__(**kwargs)\n","        self.supports_masking = True\n","        self.rate = rate\n","        self.start_step = start_step\n","        self.dropout = tf.keras.layers.Dropout(rate, noise_shape=noise_shape)\n","\n","    def build(self, input_shape):\n","        super().build(input_shape)\n","        agg = tf.VariableAggregation.ONLY_FIRST_REPLICA\n","        self._train_counter = tf.Variable(0, dtype=\"int64\", aggregation=agg, trainable=False)\n","\n","    def call(self, inputs, training=False):\n","        x = tf.cond(\n","            self._train_counter < self.start_step,\n","            lambda: inputs,\n","            lambda: self.dropout(inputs, training=training),\n","        )\n","        if training:\n","            self._train_counter.assign_add(1)\n","        return x\n","\n","\n","class CausalDWConv1D(tf.keras.layers.Layer):\n","    # Causal Depth Wise Convolution\n","    def __init__(\n","        self,\n","        kernel_size=17,\n","        dilation_rate=1,\n","        use_bias=False,\n","        depthwise_initializer=\"glorot_uniform\",\n","        strides=1,\n","        name=\"\",\n","\n","        **kwargs,\n","    ):\n","        super().__init__(name=name, **kwargs)\n","        self.causal_pad = tf.keras.layers.ZeroPadding1D(\n","            (dilation_rate * (kernel_size - 1), 0), name=name + \"_pad\"\n","        )\n","        self.dw_conv = tf.keras.layers.DepthwiseConv1D(\n","            kernel_size,\n","            strides=strides,\n","            dilation_rate=dilation_rate,\n","            padding=\"valid\",\n","            use_bias=use_bias,\n","            depthwise_initializer=depthwise_initializer,\n","            name=name + \"_dwconv\",\n","        )\n","        self.supports_masking = True\n","\n","    def call(self, inputs):\n","        x = self.causal_pad(inputs)\n","        x = self.dw_conv(x)\n","        return x\n","\n","\n","def Conv1DBlock(\n","    channel_size,\n","    kernel_size,\n","    dilation_rate=1,\n","    drop_rate=0.0,\n","    expand_ratio=2,\n","    activation=\"relu6\", #\"swish\",\n","    causal=True,\n","    name=None,\n","    strides=1,\n","    use_eca=True,\n","):\n","    \"\"\"\n","    efficient conv1d block, @hoyso48\n","    \"\"\"\n","    if name is None:\n","        name = str(tf.keras.backend.get_uid(\"mbblock\"))\n","\n","    # Expansion phase\n","    def apply(inputs):\n","        channels_in = tf.keras.backend.int_shape(inputs)[-1]\n","        channels_expand = channels_in * expand_ratio\n","\n","        skip = inputs\n","\n","        x = tf.keras.layers.Dense(\n","            channels_expand, use_bias=True,  name=name + \"_expand_conv\"\n","        )(inputs)\n","        x = tf.keras.layers.BatchNormalization(\n","            name=name + \"expand_bn\",\n","        )(x)\n","        x = tf.keras.layers.Activation(activation, name=name + \"expand_activation\")(x)\n","\n","        # Depthwise Convolution\n","        if causal:\n","          x = CausalDWConv1D(\n","            kernel_size, dilation_rate=dilation_rate, use_bias=False, strides=strides,name=name + \"_dwconv\"\n","          )(x)\n","        else:\n","          x=tf.keras.layers.DepthwiseConv1D(\n","            kernel_size,\n","            strides=strides,\n","            dilation_rate=dilation_rate,\n","            padding=\"same\",\n","            use_bias=False,\n","            depthwise_initializer=\"glorot_uniform\",\n","            name=name + \"_dwconv\")(x)\n","          \n","        x=tf.keras.layers.BatchNormalization()(x)  \n","        x = tf.keras.layers.Activation(activation)(x)\n","\n","        if use_eca:\n","            x = ECA()(x)  # efficient channel attention\n","\n","        x = tf.keras.layers.Dense(channel_size, use_bias=False, name=name + \"_project_conv\")(x)\n","        x = tf.keras.layers.BatchNormalization(name=name + \"_bn\")(x)\n","\n","        if channels_in == channel_size:\n","       \n","            if drop_rate > 0:\n","                x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None, 1, 1), name=name + \"_drop\")(x)\n","            if strides>1:\n","                skip=tf.keras.layers.MaxPooling1D(strides)(skip)\n","            x = tf.keras.layers.add([x, skip], name=name + \"_add\")\n","\n","        return x\n","\n","    return apply\n","\n","\n","\n","\n","def build_model1(\n","    output_dim,\n","    max_len=64,\n","    dropout_step=0,\n","    dim=192,\n","    input_pad=-100,\n","    with_transformer=True,\n","    drop_rate=0.2,\n","):\n","    inp = tf.keras.Input(shape=(max_len, Constants.CHANNELS), dtype=tf.float32, name=\"inputs\")\n","    #x=inp\n","    x = tf.keras.layers.Masking(mask_value=input_pad, input_shape=(max_len, Constants.CHANNELS))(\n","        inp\n","    )\n","    ksize = 17\n","    num_heads=6\n","    x = tf.keras.layers.Dense(dim, use_bias=False, name=\"stem_conv\")(x)\n","    x = tf.keras.layers.BatchNormalization(name=\"stem_bn\")(x)\n","\n","    x = Conv1DBlock(dim, ksize, drop_rate=drop_rate)(x)\n","    x = Conv1DBlock(dim, ksize, drop_rate=drop_rate)(x)\n","    x = Conv1DBlock(dim, ksize, drop_rate=drop_rate)(x)\n","    if with_transformer:\n","        x = ConformerBlock(dim=dim,dim_head=dim//num_heads,num_heads=num_heads,dropout=drop_rate,max_len=max_len)(x)\n","\n","\n","\n","\n","    x = Conv1DBlock(dim, ksize, drop_rate=drop_rate)(x)\n","    x = Conv1DBlock(dim, ksize, drop_rate=drop_rate)(x)\n","    x = Conv1DBlock(dim, ksize, drop_rate=drop_rate)(x)\n","    if with_transformer:\n","         x = ConformerBlock(dim=dim,dim_head=dim//num_heads,num_heads=num_heads,dropout=drop_rate,max_len=max_len)(x)\n","\n","    x = tf.keras.layers.AvgPool1D(2, 2)(x) # [B,T,dim]\n","    #x = tf.keras.layers.AvgPool1D(1, 1)(x) # [B,T,dim]\n","\n","    #lstm2 = tf.keras.layers.LSTM(units=dim//2, return_sequences=True,dtype=\"float32\") #[B,T,dim//2]\n","    #x2 = tf.keras.layers.Bidirectional(lstm2)(x) #[B,T,dim]\n","\n","    #x2=tf.keras.layers.BatchNormalization()(x2)\n","    #x2=Unmask()(x)\n","\n","    x2=tf.keras.layers.Dense(output_dim)(x)\n","    #x2=MaskLoss()(x2)\n","\n","    soft=tf.keras.layers.Activation('softmax', dtype='float32')(x2)\n","\n","    logsoft=tf.keras.layers.Activation('log_softmax',dtype='float32',name=\"internal\")(x2)\n","\n","\n","\n","    x4=tf.keras.layers.Dense(dim)(soft)\n","    x=Residual()([x,x4])\n","    x=tf.keras.layers.BatchNormalization()(x)\n","\n","    x = Conv1DBlock(dim, ksize, drop_rate=drop_rate)(x)\n","    x = Conv1DBlock(dim, ksize, drop_rate=drop_rate)(x)\n","    x = Conv1DBlock(dim, ksize, drop_rate=drop_rate)(x)\n","\n","    if with_transformer:\n","        x = ConformerBlock(dim=dim,dim_head=dim//num_heads,num_heads=num_heads,dropout=drop_rate,max_len=max_len//2)(x)\n","\n","    x = Conv1DBlock(dim, ksize, drop_rate=drop_rate)(x)\n","    x = Conv1DBlock(dim, ksize, drop_rate=drop_rate)(x)\n","    x = Conv1DBlock(dim, ksize, drop_rate=drop_rate)(x)\n","\n","    if with_transformer:\n","         x = ConformerBlock(dim=dim,dim_head=dim//num_heads,num_heads=num_heads,dropout=drop_rate,max_len=max_len//2)(x)\n","\n","    #lstm = tf.keras.layers.LSTM(units=dim//2, return_sequences=True,dtype=\"float32\")\n","    #x = tf.keras.layers.Bidirectional(lstm)(x)\n","    #x=tf.keras.layers.BatchNormalization()(x)\n","\n","    x = LateDropout(0.5, start_step=dropout_step)(x)\n","\n","    #x=Unmask()(x)\n","    x=tf.keras.layers.Dense(output_dim)(x)\n","    #x=MaskLoss()(x)\n","\n","    output = tf.keras.layers.Activation(\"log_softmax\",name=\"final\",dtype=\"float32\")(x)  # logits\n","\n","    model = tf.keras.Model(inp, outputs=[output,logsoft])\n","\n","    return model\n","\n","\n","def build_evit(output_dim, max_len, input_pad, dim,  dropout_step=0,drop_rate=0.0):\n","    inp = tf.keras.Input(shape=(max_len, Constants.CHANNELS), dtype=tf.float32, name=\"inputs\")\n","    output=efficientvit_seg_a0()(inp)\n","    model=tf.keras.Model(inp,outputs=output)\n","    return model\n","\n","\n","def get_model(output_dim, max_len, dim, input_pad,dropout_step=0,drop_rate=0.0):\n","\n","    #model = build_model1(output_dim, max_len=max_len, input_pad=input_pad, dim=dim,  dropout_step=dropout_step,drop_rate=drop_rate)\n","\n","    \n","    model = build_evit(output_dim, max_len=max_len, input_pad=input_pad, dim=dim,  dropout_step=dropout_step,drop_rate=drop_rate)\n","\n","    return model\n"]},{"cell_type":"markdown","metadata":{"id":"piKWNcVHYi15"},"source":["# Configuration"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"7e1LGyFWYi16"},"outputs":[],"source":["from functools import lru_cache\n","\n","@lru_cache(maxsize=None)\n","def get_strategy():\n","    logical_devices = tf.config.list_logical_devices()\n","    # Check if TPU is available\n","\n","    gpu_available = any(\"GPU\" in device.name for device in logical_devices)\n","    strategy = None\n","    is_tpu = False\n","    try:\n","        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","        print(\"Running on TPU \", tpu.master())\n","        is_tpu = True\n","    except ValueError:\n","        is_tpu = False\n","\n","    if is_tpu:\n","        tf.config.experimental_connect_to_cluster(tpu)\n","        tf.tpu.experimental.initialize_tpu_system(tpu)\n","\n","        print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n","\n","        strategy = tf.distribute.TPUStrategy(tpu)\n","        #disable_eager_execution()  # LSTM layer can't use bfloat16 unless we do this.\n","\n","    else:\n","        if gpu_available:\n","\n","            ngpu = len(gpus)\n","            print(\"Num GPUs Available: \", ngpu)\n","            if ngpu > 1:\n","                strategy = tf.distribute.MirroredStrategy()\n","            else:\n","                strategy = tf.distribute.get_strategy()\n","\n","        else:\n","            print(\"Runing on CPU\")\n","            strategy = tf.distribute.get_strategy()\n","    replicas = strategy.num_replicas_in_sync\n","\n","    print(f\"get strategy replicas: {replicas}\")\n","\n","    return strategy, replicas, is_tpu\n","\n","\n","class CFG:\n","    # These 3 variables are update dynamically later by calling update_config_with_strategy.\n","    strategy = None  # type: ignore\n","    replicas = 1\n","    is_tpu = False\n","\n","    save_output = True\n","    input_path = \"/kaggle/input/asl-fingerspelling\"\n","    output_path = \"/kaggle/working\"\n","    records_path=\"/kaggle/input/sign-tfrecords\"\n","\n","\n","    seed = 42\n","    verbose = 1  # 0) silent 1) progress bar 2) one line per epoch\n","\n","    # max number of frames\n","    #max_len = 256\n","    max_len = 384\n","    replicas = 1\n","\n","    lr = 3e-4   # 5e-4\n","    weight_decay = 3e-5  # 4e-4\n","    epochs = 400\n","\n","    batch_size=128\n","\n","\n","    snapshot_epochs = []  # type: ignore\n","    swa_epochs = list(range(3*(epochs//4),epochs+1))\n","\n","\n","    fp16=True\n","\n","    awp = False\n","    awp_lambda = 0.05\n","    awp_start_epoch = epochs//20\n","    dropout_start_epoch = epochs//20\n","    resume = 0\n","\n","    dim = 384\n","\n","    comment = f\"model-{dim}-seed{seed}\"\n","    output_dim = 60\n","    num_eval = 6\n","\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"HCKh-AxTYi16"},"outputs":[],"source":["\n","def update_config_with_strategy(config):\n","    # cfg is configuration instance\n","    #strategy, replicas, is_tpu = get_strategy()\n","    if tpu_strategy is not None:\n","      strategy=tpu_strategy\n","      replicas=8\n","      is_tpu=True\n","\n","      gs_bucket=\"gs://kds-0c311d89a1e30bf24873d79efc37a0556315e01ba38961c38c99f592\"\n","      config.records_path=gs_bucket\n","      config.input_path=\"/content/drive/MyDrive/kaggle-asl/asl-fingerspelling\"\n","      config.output_path = \"/content/drive/MyDrive/kaggle/working\"\n","      print(\"updated paths\",gs_bucket)\n","\n","    else:\n","      strategy,replicas,is_tpu=get_strategy()\n","    print(\"Strategy\",strategy)\n","\n","    config.strategy = strategy\n","    config.replicas = replicas\n","    config.is_tpu = is_tpu\n","    config.lr = config.lr * replicas\n","    config.batch_size = config.batch_size * replicas\n","    return config"]},{"cell_type":"markdown","metadata":{"id":"5msRCmt0Yi16"},"source":["\n","# Training"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"j_tHWSs8Yi16"},"outputs":[],"source":["\n","def count_data_items(dataset):\n","    dataset_size = 0\n","    for _ in dataset:\n","        dataset_size += 1\n","    return dataset_size\n","\n","\n","def interp1d_(x, target_len):\n","    target_len = tf.maximum(1, target_len)\n","    x = tf.image.resize(x, (target_len, tf.shape(x)[1]))\n","    return x\n","\n","\n","def tf_nan_mean(x, axis=0, keepdims=False):\n","    return tf.reduce_sum(\n","        tf.where(tf.math.is_nan(x), tf.zeros_like(x), x), axis=axis, keepdims=keepdims\n","    ) / tf.reduce_sum(\n","        tf.where(tf.math.is_nan(x), tf.zeros_like(x), tf.ones_like(x)), axis=axis, keepdims=keepdims\n","    )\n","\n","\n","def tf_nan_std(x, center=None, axis=0, keepdims=False):\n","    if center is None:\n","        center = tf_nan_mean(x, axis=axis, keepdims=True)\n","    d = x - center\n","    return tf.math.sqrt(tf_nan_mean(d * d, axis=axis, keepdims=keepdims))\n","\n","\n","def flip_lr(x):\n","    if x.shape[1] == Constants.ROWS_PER_FRAME:\n","        LHAND = Constants.LHAND\n","        RHAND = Constants.RHAND\n","        LLIP = Constants.LLIP\n","        RLIP = Constants.RLIP\n","        LEYE = Constants.LEYE\n","        REYE = Constants.REYE\n","        LNOSE = Constants.LNOSE\n","        RNOSE = Constants.RNOSE\n","        LPOSE = Constants.LPOSE\n","        RPOSE = Constants.RPOSE\n","    else:\n","        LHAND = Constants.LANDMARK_INDICES[\"LHAND\"]\n","        RHAND = Constants.LANDMARK_INDICES[\"RHAND\"]\n","        LLIP = Constants.LANDMARK_INDICES[\"LLIP\"]\n","        RLIP = Constants.LANDMARK_INDICES[\"RLIP\"]\n","        LEYE = Constants.LANDMARK_INDICES[\"LEYE\"]\n","        REYE = Constants.LANDMARK_INDICES[\"REYE\"]\n","        LNOSE = Constants.LANDMARK_INDICES[\"LNOSE\"]\n","        RNOSE = Constants.LANDMARK_INDICES[\"RNOSE\"]\n","        LPOSE = Constants.LANDMARK_INDICES[\"LPOSE\"]\n","        RPOSE = Constants.LANDMARK_INDICES[\"RPOSE\"]\n","\n","    x, y = tf.unstack(x, axis=-1)\n","    x = 1 - x\n","    new_x = tf.stack([x, y], -1)\n","    new_x = tf.transpose(new_x, [1, 0, 2])\n","    lhand = tf.gather(new_x, LHAND, axis=0)\n","    rhand = tf.gather(new_x, RHAND, axis=0)\n","    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(LHAND)[..., None], rhand)\n","    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(RHAND)[..., None], lhand)\n","    llip = tf.gather(new_x, LLIP, axis=0)\n","    rlip = tf.gather(new_x, RLIP, axis=0)\n","    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(LLIP)[..., None], rlip)\n","    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(RLIP)[..., None], llip)\n","    lpose = tf.gather(new_x, LPOSE, axis=0)\n","    rpose = tf.gather(new_x, RPOSE, axis=0)\n","    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(LPOSE)[..., None], rpose)\n","    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(RPOSE)[..., None], lpose)\n","    leye = tf.gather(new_x, LEYE, axis=0)\n","    reye = tf.gather(new_x, REYE, axis=0)\n","    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(LEYE)[..., None], reye)\n","    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(REYE)[..., None], leye)\n","    lnose = tf.gather(new_x, LNOSE, axis=0)\n","    rnose = tf.gather(new_x, RNOSE, axis=0)\n","    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(LNOSE)[..., None], rnose)\n","    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(RNOSE)[..., None], lnose)\n","    new_x = tf.transpose(new_x, [1, 0, 2])\n","    return new_x\n","\n","\n","def resample(x, rate=(0.8, 1.2)):\n","    rate = tf.random.uniform((), rate[0], rate[1])\n","    length = tf.shape(x)[0]\n","    new_size = tf.cast(rate * tf.cast(length, tf.float32), tf.int32)\n","    new_x = interp1d_(x, new_size)\n","    return new_x\n","\n","\n","def spatial_random_affine(\n","    xyz,\n","    scale=(0.8, 1.2),\n","    shear=(-0.1, 0.1),\n","    shift=(-0.1, 0.1),\n","    degree=(-20, 20),\n","):\n","    center = tf.constant([0.5, 0.5])\n","    if degree is not None:\n","        xy = xyz[..., :2]\n","        z = xyz[..., 2:]\n","        xy -= center\n","        degree = tf.random.uniform((), *degree)\n","        radian = degree / 180 * np.pi\n","        c = tf.math.cos(radian)\n","        s = tf.math.sin(radian)\n","        rotate_mat = tf.identity(\n","            [\n","                [c, s],\n","                [-s, c],\n","            ]\n","        )\n","        xy = xy @ rotate_mat\n","        xy = xy + center\n","        xyz = tf.concat([xy, z], axis=-1)\n","\n","    if scale is not None:\n","        scale = tf.random.uniform((), *scale)\n","        xyz = scale * xyz\n","\n","    if shear is not None:\n","        xy = xyz[..., :2]\n","        z = xyz[..., 2:]\n","        shear_x = shear_y = tf.random.uniform((), *shear)\n","        if tf.random.uniform(()) < 0.5:\n","            shear_x = 0.0\n","        else:\n","            shear_y = 0.0\n","        shear_mat = tf.identity([[1.0, shear_x], [shear_y, 1.0]])\n","        xy = xy @ shear_mat\n","        xyz = tf.concat([xy, z], axis=-1)\n","\n","    if shift is not None:\n","        shift = tf.random.uniform((), *shift)\n","        xyz = xyz + shift\n","\n","    return xyz\n","\n","\n","def temporal_mask(x, size=[1, 20], mask_value=float(\"nan\")):\n","    l0 = tf.shape(x)[0]\n","    if size[1] > l0 // 8:\n","        size[1] = l0 // 8\n","        if size[1] <= size[0]:\n","            size[1] = size[0]+1\n","    mask_size = tf.random.uniform((), *size, dtype=tf.int32)\n","    mask_offset = tf.random.uniform((), 0, tf.clip_by_value(l0 - mask_size, 1, l0), dtype=tf.int32)\n","    x = tf.tensor_scatter_nd_update(\n","        x,\n","        tf.range(mask_offset, mask_offset + mask_size)[..., None],\n","        tf.fill([mask_size, tf.shape(x)[1], 2], mask_value),\n","    )\n","    return x\n","\n","\n","def spatial_mask(x, size=(0.1, 0.3), mask_value=float(\"nan\")):\n","    mask_offset_y = tf.random.uniform(())\n","    mask_offset_x = tf.random.uniform(())\n","    mask_size = tf.random.uniform((), *size)\n","    mask_x = (mask_offset_x < x[..., 0]) & (x[..., 0] < mask_offset_x + mask_size)\n","    mask_y = (mask_offset_y < x[..., 1]) & (x[..., 1] < mask_offset_y + mask_size)\n","    mask = mask_x & mask_y\n","    x = tf.where(mask[..., None], mask_value, x)\n","    return x\n","\n","\n","\n","def augment_fn(x):\n","    # shape (T,F)\n","    x = tf.reshape(x, (tf.shape(x)[0], -1, 2))\n","    if tf.random.uniform(()) < 0.8:\n","        x = resample(x, (0.5, 1.5))\n","    if tf.random.uniform(()) < 0.6:\n","        x = flip_lr(x)\n","    if tf.random.uniform(()) < 0.75:\n","        x = spatial_random_affine(x)\n","    if tf.random.uniform(()) < 0.5:\n","        x = temporal_mask(x)\n","    if tf.random.uniform(()) < 0.5:\n","        x = spatial_mask(x)\n","    x = tf.reshape(x, (tf.shape(x)[0], -1))\n","    return x\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"jYUGdwEDYi17"},"outputs":[],"source":["\n","class Snapshot(tf.keras.callbacks.Callback):\n","\n","    def __init__(self,save_name,snapshot_epochs=[]):\n","        super().__init__()\n","        self.snapshot_epochs = snapshot_epochs\n","        self.save_name = save_name\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        # logs is a dictionary\n","        if epoch in self.snapshot_epochs: # your custom condition\n","            self.model.save_weights(f\"{self.save_name}-epoch{epoch}.h5\")\n","        self.model.save_weights(f\"{self.save_name}-last.h5\")\n","\n","class Preprocess(tf.keras.layers.Layer):\n","    def __init__(self, max_len, normalize=True, **kwargs):\n","        super().__init__(**kwargs)\n","        self.max_len = max_len\n","        self.center = Constants.CENTER_INDICES\n","        self.normalize = normalize\n","\n","    # preprocess a batch of data\n","    def call(self, x):\n","        # rank is 3: [B,T,F]\n","        # if your input is just [T,F], extend its dimesnion before calling.\n","\n","        x = tf.reshape(x, (tf.shape(x)[0], tf.shape(x)[1], Constants.NUM_NODES, 2))\n","        # dimensions now are [B,T,F//2,2]\n","\n","        x_selected = x\n","        if self.normalize:\n","            mean = tf_nan_mean(tf.gather(x, self.center, axis=2), axis=[1, 2], keepdims=True)\n","            mean = tf.where(tf.math.is_nan(mean), tf.constant(0.5, x.dtype), mean)\n","            std = tf_nan_std(x_selected, center=mean, axis=[1, 2], keepdims=True)\n","            x = (x_selected - mean) / std\n","        else:\n","            x = x_selected\n","\n","        dx = tf.cond(\n","            tf.shape(x)[1] > 1,\n","            lambda: tf.pad(x[:, 1:] - x[:, :-1], [[0, 0], [0, 1], [0, 0], [0, 0]]),\n","            lambda: tf.zeros_like(x),\n","        )\n","\n","        dx2 = tf.cond(\n","            tf.shape(x)[1] > 2,\n","            lambda: tf.pad(x[:, 2:] - x[:, :-2], [[0, 0], [0, 2], [0, 0], [0, 0]]),\n","            lambda: tf.zeros_like(x),\n","        )\n","        length = tf.shape(x)[1]\n","\n","        x = tf.concat(\n","            [\n","                tf.reshape(x, (-1, length, 2 * Constants.NUM_NODES)),  # x1,y1,x2,y2,...\n","                tf.reshape(dx, (-1, length, 2 * Constants.NUM_NODES)),\n","                tf.reshape(dx2, (-1, length, 2 * Constants.NUM_NODES)),\n","            ],\n","            axis=-1,\n","        )\n","\n","        # x1,y1,x2,y2,...dx1,dy1,dx2,dy2,...\n","        x = tf.where(tf.math.is_nan(x), tf.constant(0.0, x.dtype), x)\n","        return x\n","\n","\n","def pad_if_short(x, max_len):\n","    # shape (T,F)\n","    pad_len = max_len - tf.shape(x)[0]\n","    padding = tf.ones((pad_len, tf.shape(x)[1]), dtype=x.dtype) * Constants.INPUT_PAD\n","    x = tf.concat([x, padding], axis=0)\n","    return x\n","\n","\n","def shrink_if_long(x, max_len):\n","    # shape is [T,F]\n","    if tf.shape(x)[0] > max_len:\n","        # we need to extend the dimension to [T,F,channels]  for tf.image.resize\n","        x = tf.image.resize(x[..., None], (max_len, tf.shape(x)[1]))\n","        x = tf.squeeze(x, axis=2)\n","\n","    return x\n","\n","def preprocess(x, max_len, do_pad=True):\n","    # shape (T,F)\n","    x = shrink_if_long(x, max_len=max_len)\n","    # Preprocess expects a batch, so we extend the dimension to (None,T,F), then reduce the output back to (T,F).\n","    x = tf.cast(Preprocess(max_len=max_len)(x[None, ...])[0], tf.float32)\n","\n","    if do_pad:  # we can avoid this step if there is batch padding\n","        x = pad_if_short(x, max_len=max_len)\n","        #x=tf.ensure_shape(x,(max_len,Constants.CHANNELS))\n","    else:\n","        #x=tf.ensure_shape(x,(None,Constants.CHANNELS))\n","        pass\n","    return x"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"FdtpVVSbYi17"},"outputs":[],"source":["\n","def decode_tfrec(record_bytes):\n","    features = tf.io.parse_single_example(\n","        record_bytes,\n","        {\n","            \"coordinates\": tf.io.VarLenFeature(tf.float32),\n","            \"label\": tf.io.VarLenFeature(tf.int64),\n","        },\n","    )\n","    coords = tf.sparse.to_dense(features[\"coordinates\"])\n","    coords = tf.reshape(coords, (-1, Constants.NUM_INPUT_FEATURES))\n","    label = tf.sparse.to_dense(features[\"label\"])\n","\n","    #coords=tf.ensure_shape(coords,(None,Constants.NUM_INPUT_FEATURES))\n","    #label=tf.ensure_shape(label,(None,))\n","\n","\n","    return (coords, label)\n","\n","def ensure_shapes(x,y,batch_size,max_len):\n","  x=tf.ensure_shape(x,(batch_size,max_len,Constants.CHANNELS))\n","  y=tf.ensure_shape(y,(batch_size,Constants.MAX_STRING_LEN))\n","  return x,y"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"ImAgehPoYi18"},"outputs":[],"source":["\n","def get_dataset(\n","    filenames,\n","    max_len,\n","    batch_size=64,\n","    drop_remainder=False,\n","    augment=False,\n","    shuffle_buffer=None,\n","):\n","    ignore_order = tf.data.Options()\n","    ignore_order.experimental_deterministic = False\n","\n","\n","    ds = tf.data.TFRecordDataset(\n","        filenames, num_parallel_reads=tf.data.AUTOTUNE, compression_type=\"GZIP\"\n","    )\n","    ds.with_options(ignore_order)\n","    ds = ds.map(decode_tfrec, tf.data.AUTOTUNE)\n","\n","    if augment:\n","        ds = ds.map(lambda x, y: (augment_fn(x), y), tf.data.AUTOTUNE)\n","\n","    ds = ds.map(lambda x, y: (preprocess(x, max_len=max_len, do_pad=False), y), tf.data.AUTOTUNE)\n","\n","    if shuffle_buffer is not None:\n","        ds = ds.shuffle(shuffle_buffer)\n","\n","    ds = ds.padded_batch(\n","        batch_size,\n","        padding_values=(\n","            tf.constant(Constants.INPUT_PAD, dtype=tf.float32),\n","            tf.constant(Constants.LABEL_PAD, dtype=tf.int64),\n","        ),\n","        padded_shapes=([max_len, Constants.CHANNELS], [Constants.MAX_STRING_LEN]),\n","        drop_remainder=drop_remainder,\n","    )\n","\n","    #tf.data.experimental.assert_cardinality(len(labels) // BATCH_SIZE)\n","    ds.map(lambda x,y: ensure_shapes(x,y,batch_size,max_len),tf.data.AUTOTUNE)\n","    ds = ds.prefetch(tf.data.AUTOTUNE)\n","\n","    return ds\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"4HDYkwwgYi18"},"outputs":[],"source":["\n","def train_run(train_files, valid_files, config, num_train, num_valid,experiment_id=0, use_tfrecords=True,summary=True):\n","    #gc.collect()\n","    #tf.keras.backend.clear_session()\n","\n","\n","    if config.fp16:\n","        if config.is_tpu:\n","            policy = \"mixed_bfloat16\"\n","        else:\n","            policy = \"mixed_float16\"\n","    else:\n","        policy = \"float32\"\n","\n","\n","    tf.keras.mixed_precision.set_global_policy(policy)\n","    print(f\"\\n... TWO IMPORTANT ASPECTS OF THE GLOBAL MIXED PRECISION POLICY:\")\n","    print(f'\\t--> COMPUTE DTYPE  : {tf.keras.mixed_precision.global_policy().compute_dtype}')\n","    print(f'\\t--> VARIABLE DTYPE : {tf.keras.mixed_precision.global_policy().variable_dtype}')\n","    augment_train= True\n","    if config.is_tpu:\n","      shuffle_buffer = 16384 #4096\n","    else:\n","      shuffle_buffer=4096\n","    print(\"shuffle_buffer\",shuffle_buffer)\n","    train_ds = get_dataset(\n","        train_files,\n","        max_len=config.max_len,\n","        batch_size=config.batch_size,\n","        drop_remainder=True,\n","        augment=augment_train,\n","        shuffle_buffer=shuffle_buffer,\n","    )\n","    if valid_files is not None:\n","        valid_ds = get_dataset(\n","            valid_files,\n","            max_len=config.max_len,\n","            batch_size=config.batch_size,\n","            drop_remainder=True\n","        )\n","    else:\n","        valid_ds = None\n","        valid_files = []\n","\n","\n","    #num_train = count_data_items(train_ds)\n","    #num_valid = count_data_items(valid_ds)\n","    #print(\"counts\",num_train, num_valid, config.batch_size)\n","    #assert False\n","    # exit()\n","\n","    steps_per_epoch = num_train // config.batch_size\n","    dropout_step = config.dropout_start_epoch * steps_per_epoch\n","    strategy = config.strategy\n","    with strategy.scope():\n","        model = get_model(\n","            max_len=config.max_len,\n","            output_dim=config.output_dim,\n","            input_pad=Constants.INPUT_PAD,\n","            dim=config.dim,\n","            dropout_step=dropout_step,\n","            drop_rate=0.1\n","        )\n","\n","        base_lr = config.lr\n","        lr_schedule = CosineDecay(\n","            initial_learning_rate=base_lr / 10,\n","            decay_steps=int(0.95 * steps_per_epoch * config.epochs),\n","            alpha=0.005,\n","            name=None,\n","            warmup_target=base_lr,\n","            warmup_steps=int(0.05 * steps_per_epoch * config.epochs),\n","        )\n","\n","        #opt = tf.keras.optimizers.AdamW(learning_rate=lr_schedule, weight_decay=config.weight_decay)\n","        radam=tfa.optimizers.RectifiedAdam(learning_rate=lr_schedule,weight_decay=config.weight_decay)\n","        ranger = tfa.optimizers.Lookahead(radam, sync_period=6, slow_step_size=0.5)\n","        opt=ranger\n","        awp_step = config.awp_start_epoch * steps_per_epoch\n","        if config.awp:\n","            model = AWP(model.input, model.output, delta=config.awp_lambda, eps=0., start_step=awp_step)\n","            print(\"Using AWP\")\n","\n","        ctc_loss1 = CTCLoss(pad_token_idx=Constants.LABEL_PAD)\n","        ctc_loss2 = CTCLoss(pad_token_idx=Constants.LABEL_PAD)\n","        loss=[ctc_loss1]\n","        loss_weights=[1.0]\n","        if not config.is_tpu:\n","          metrics=metrics= [LevDistanceMetric(),]\n","        else:\n","          metrics=None\n","        model.compile(\n","          optimizer=opt,\n","          loss=loss,\n","          loss_weights=loss_weights,\n","          metrics= metrics,\n","          #steps_per_execution=16\n","        )\n","\n","\n","\n","    if summary:\n","        print()\n","        model.summary()\n","        print()\n","        print(train_ds, valid_ds)\n","        print()\n","    print(f\"---------experiment {experiment_id}---------\")\n","    print(f\"train:{num_train} \")\n","    print()\n","\n","    if config.resume:\n","        print(f\"resume from epoch{config.resume}\")\n","        model.load_weights(f\"{config.output_path}/{config.comment}-exp{experiment_id}-last.h5\")\n","        if train_ds is not None:\n","            model.evaluate(train_ds.take(steps_per_epoch))\n","        if valid_ds is not None:\n","            model.evaluate(valid_ds)\n","\n","    tb_logger = tf.keras.callbacks.TensorBoard(\n","        log_dir=config.output_path,\n","    )\n","    sv_loss = tf.keras.callbacks.ModelCheckpoint(\n","        f\"{config.output_path}/{config.comment}-exp{experiment_id}-best.h5\",\n","        monitor=\"val_loss\",\n","        verbose=1,\n","        save_best_only=True,\n","        save_weights_only=True,\n","        mode=\"min\",\n","        save_freq=\"epoch\",\n","    )\n","\n","    # Callback function to check transcription on the val set.\n","    # validation_callback = CallbackEval(model, valid_ds)\n","    memory_usage = MemoryUsageCallbackExtended()\n","    swa = SWA(\n","        f\"{config.output_path}/{config.comment}-exp{experiment_id}\",\n","        config.swa_epochs,\n","        strategy=strategy,\n","        train_ds=train_ds,\n","        valid_ds=valid_ds,\n","    )\n","    callbacks = []\n","    if config.save_output:\n","        #callbacks.append(tb_logger)\n","        callbacks.append(swa)\n","        callbacks.append(sv_loss)\n","    #callbacks.append(memory_usage)\n","        callbacks.append(tf.keras.callbacks.TerminateOnNaN())\n","    # callbacks.append(validation_callback)\n","\n","    history = model.fit(\n","        train_ds,\n","        epochs=config.epochs - config.resume,\n","        #steps_per_epoch=steps_per_epoch,\n","        #validation_steps=num_valid // config.batch_size,\n","        callbacks=callbacks,\n","        validation_data=valid_ds,\n","        verbose=config.verbose,\n","    )\n","\n","    if config.save_output:  # reload the saved best weights checkpoint\n","        saved_based_model = f\"{config.output_path}/{config.comment}-exp{experiment_id}-best.h5\"\n","        if os.path.exists(saved_based_model):\n","            model.load_weights(saved_based_model)\n","        else:\n","            print(f\"Warning: could not find {saved_based_model}\")\n","    if valid_ds is not None:\n","        print(\"evaluate\")\n","        cv = model.evaluate(valid_ds, verbose=config.verbose)\n","    else:\n","        cv = None\n","    return model, cv, history\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"YpxT9BTFYi18"},"outputs":[],"source":["\n","def train(config, experiment_id=0, use_supplemental=True,use_chicago=False):\n","    #tf.keras.backend.clear_session()\n","    if config.strategy is None:\n","      update_config_with_strategy(config)\n","    print(f\"using {config.replicas} replicas\")\n","    print(f\"batch size {config.batch_size}\")\n","    print(f\"learning rate {config.lr}\")\n","    print(f\"fp16={config.fp16}\")\n","    seed_everything(config.seed)\n","\n","\n","    all_filenames = sorted(tf.io.gfile.glob(config.records_path+\"/*.tfrecord\"))\n","    regular = [x for x in all_filenames if \"train\" in x]\n","    supp = [x for x in all_filenames if \"supp\" in x]\n","    chicago =[x for x in all_filenames if \"chicago\" in x]\n","    print(regular)\n","\n","\n","    data_filenames = regular.copy()\n","    if use_supplemental:\n","        data_filenames += supp\n","    if use_chicago:\n","        data_filenames +=chicago\n","    print(\"Using TFRECORDS\")\n","    print(\"regular\",len(regular))\n","    print(\"Supplemental:\",use_supplemental,len(supp))\n","    print(\"Chicago:\",use_chicago,len(chicago))\n","\n","\n","    valid_files = data_filenames[: config.num_eval]  # first part in list\n","    train_files = data_filenames[config.num_eval :]\n","\n","    if use_chicago:\n","      train_files += regular[config.num_eval:]\n","    random.shuffle(train_files)\n","\n","\n","    if use_chicago:\n","        num_train = 7418 * 32  # with chicago (x 2 regular)\n","    elif use_supplemental:\n","        num_train = 3567 * 32  # with supplemental\n","    else:\n","        num_train = 1912 * 32  # without supplemental\n","\n","    # cut in half\n","    train_files=train_files[:len(train_files)//2]\n","    num_train=num_train//2\n","\n","    num_valid=187*32\n","\n","    train_run(\n","        train_files,\n","        valid_files,\n","        config,\n","        num_train,\n","        num_valid,\n","        summary=True,\n","        experiment_id=experiment_id,\n","        use_tfrecords=True,\n","    )\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"lfC8z_wLYi19"},"outputs":[],"source":["gc.collect()\n","tf.keras.backend.clear_session()"]},{"cell_type":"markdown","metadata":{"id":"BVIhC2jeYi19"},"source":["# Train It!"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4944367,"status":"ok","timestamp":1691956433975,"user":{"displayName":"Shai Ronen","userId":"11425665314369101818"},"user_tz":360},"id":"5UdMh9V7Yi19","outputId":"cb8293fb-338e-4a80-9e04-6409dc378a1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Num GPUs Available:  1\n","get strategy replicas: 1\n","Strategy <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7fc964d5ba00>\n","using 1 replicas\n","batch size 128\n","learning rate 0.0003\n","fp16=True\n","['/kaggle/input/sign-tfrecords/train_1019715464.tfrecord', '/kaggle/input/sign-tfrecords/train_1021040628.tfrecord', '/kaggle/input/sign-tfrecords/train_105143404.tfrecord', '/kaggle/input/sign-tfrecords/train_1098899348.tfrecord', '/kaggle/input/sign-tfrecords/train_1099408314.tfrecord', '/kaggle/input/sign-tfrecords/train_1133664520.tfrecord', '/kaggle/input/sign-tfrecords/train_1134756332.tfrecord', '/kaggle/input/sign-tfrecords/train_1255240050.tfrecord', '/kaggle/input/sign-tfrecords/train_128822441.tfrecord', '/kaggle/input/sign-tfrecords/train_1320204318.tfrecord', '/kaggle/input/sign-tfrecords/train_1341528257.tfrecord', '/kaggle/input/sign-tfrecords/train_1358493307.tfrecord', '/kaggle/input/sign-tfrecords/train_1365275733.tfrecord', '/kaggle/input/sign-tfrecords/train_1365772051.tfrecord', '/kaggle/input/sign-tfrecords/train_1405046009.tfrecord', '/kaggle/input/sign-tfrecords/train_1448136004.tfrecord', '/kaggle/input/sign-tfrecords/train_1497621680.tfrecord', '/kaggle/input/sign-tfrecords/train_149822653.tfrecord', '/kaggle/input/sign-tfrecords/train_152029243.tfrecord', '/kaggle/input/sign-tfrecords/train_1552432300.tfrecord', '/kaggle/input/sign-tfrecords/train_1557244878.tfrecord', '/kaggle/input/sign-tfrecords/train_1562234637.tfrecord', '/kaggle/input/sign-tfrecords/train_1643479812.tfrecord', '/kaggle/input/sign-tfrecords/train_1647220008.tfrecord', '/kaggle/input/sign-tfrecords/train_1662742697.tfrecord', '/kaggle/input/sign-tfrecords/train_1664666588.tfrecord', '/kaggle/input/sign-tfrecords/train_169560558.tfrecord', '/kaggle/input/sign-tfrecords/train_1726141437.tfrecord', '/kaggle/input/sign-tfrecords/train_175396851.tfrecord', '/kaggle/input/sign-tfrecords/train_1785039512.tfrecord', '/kaggle/input/sign-tfrecords/train_1865557033.tfrecord', '/kaggle/input/sign-tfrecords/train_1880177496.tfrecord', '/kaggle/input/sign-tfrecords/train_1905462118.tfrecord', '/kaggle/input/sign-tfrecords/train_1906357076.tfrecord', '/kaggle/input/sign-tfrecords/train_1920330615.tfrecord', '/kaggle/input/sign-tfrecords/train_1967755728.tfrecord', '/kaggle/input/sign-tfrecords/train_1969985709.tfrecord', '/kaggle/input/sign-tfrecords/train_1997878546.tfrecord', '/kaggle/input/sign-tfrecords/train_2026717426.tfrecord', '/kaggle/input/sign-tfrecords/train_2036580525.tfrecord', '/kaggle/input/sign-tfrecords/train_2072296290.tfrecord', '/kaggle/input/sign-tfrecords/train_2072876091.tfrecord', '/kaggle/input/sign-tfrecords/train_2118949241.tfrecord', '/kaggle/input/sign-tfrecords/train_234418913.tfrecord', '/kaggle/input/sign-tfrecords/train_296317215.tfrecord', '/kaggle/input/sign-tfrecords/train_349393104.tfrecord', '/kaggle/input/sign-tfrecords/train_388576474.tfrecord', '/kaggle/input/sign-tfrecords/train_425182931.tfrecord', '/kaggle/input/sign-tfrecords/train_433948159.tfrecord', '/kaggle/input/sign-tfrecords/train_450474571.tfrecord', '/kaggle/input/sign-tfrecords/train_474255203.tfrecord', '/kaggle/input/sign-tfrecords/train_495378749.tfrecord', '/kaggle/input/sign-tfrecords/train_522550314.tfrecord', '/kaggle/input/sign-tfrecords/train_527708222.tfrecord', '/kaggle/input/sign-tfrecords/train_532011803.tfrecord', '/kaggle/input/sign-tfrecords/train_5414471.tfrecord', '/kaggle/input/sign-tfrecords/train_546816846.tfrecord', '/kaggle/input/sign-tfrecords/train_566963657.tfrecord', '/kaggle/input/sign-tfrecords/train_568753759.tfrecord', '/kaggle/input/sign-tfrecords/train_614661748.tfrecord', '/kaggle/input/sign-tfrecords/train_638508439.tfrecord', '/kaggle/input/sign-tfrecords/train_649779897.tfrecord', '/kaggle/input/sign-tfrecords/train_654436541.tfrecord', '/kaggle/input/sign-tfrecords/train_683666742.tfrecord', '/kaggle/input/sign-tfrecords/train_871280215.tfrecord', '/kaggle/input/sign-tfrecords/train_882979387.tfrecord', '/kaggle/input/sign-tfrecords/train_933868835.tfrecord', '/kaggle/input/sign-tfrecords/train_939623093.tfrecord']\n","Using TFRECORDS\n","regular 68\n","Supplemental: False 53\n","Chicago: False 62\n","INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n","Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3060 Ti, compute capability 8.6\n"]},{"name":"stderr","output_type":"stream","text":["2023-08-16 11:42:38.609725: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-08-16 11:42:38.609892: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-08-16 11:42:38.609986: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-08-16 11:42:38.668016: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-08-16 11:42:38.668228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-08-16 11:42:38.668373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-08-16 11:42:38.668582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5907 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n","2023-08-16 11:42:38.673245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"]},{"name":"stdout","output_type":"stream","text":["\n","... TWO IMPORTANT ASPECTS OF THE GLOBAL MIXED PRECISION POLICY:\n","\t--> COMPUTE DTYPE  : float16\n","\t--> VARIABLE DTYPE : float32\n","shuffle_buffer 4096\n","\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," inputs (InputLayer)         [(None, 384, 732)]        0         \n","                                                                 \n"," efficient_vi_t_seg (Effici  (None, 96, 60)            515036    \n"," entViTSeg)                                                      \n","                                                                 \n","=================================================================\n","Total params: 515036 (1.96 MB)\n","Trainable params: 511500 (1.95 MB)\n","Non-trainable params: 3536 (13.81 KB)\n","_________________________________________________________________\n","\n","<_PrefetchDataset element_spec=(TensorSpec(shape=(128, 384, 732), dtype=tf.float32, name=None), TensorSpec(shape=(128, 50), dtype=tf.int64, name=None))> <_PrefetchDataset element_spec=(TensorSpec(shape=(128, 384, 732), dtype=tf.float32, name=None), TensorSpec(shape=(128, 50), dtype=tf.int64, name=None))>\n","\n","---------experiment 0---------\n","train:30592 \n","\n","Epoch 1/400\n","WARNING:tensorflow:From /home/sronen/code/.venv/lib/python3.10/site-packages/tensorflow/python/ops/ctc_ops.py:1514: alias_inplace_add (from tensorflow.python.ops.inplace_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.\n","WARNING:tensorflow:From /home/sronen/code/.venv/lib/python3.10/site-packages/tensorflow/python/ops/ctc_ops.py:1497: alias_inplace_update (from tensorflow.python.ops.inplace_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.\n"]},{"name":"stderr","output_type":"stream","text":["2023-08-16 11:43:16.738196: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8801\n","2023-08-16 11:43:16.836235: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n","2023-08-16 11:43:17.119704: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc86b884c50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-08-16 11:43:17.119727: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6\n","2023-08-16 11:43:17.134486: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n","2023-08-16 11:43:17.332444: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["    241/Unknown - 92s 221ms/step - loss: 317.3319 - Lev: 0.0000e+00"]},{"name":"stderr","output_type":"stream","text":["2023-08-16 11:44:13.840704: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 11185391472924617064\n","2023-08-16 11:44:13.840748: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6429279949890963124\n","2023-08-16 11:44:13.840763: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 929283034547341168\n","2023-08-16 11:44:13.840774: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 4019741907751481273\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_final_loss available, skipping.\n","241/241 [==============================] - 100s 253ms/step - loss: 317.3319 - Lev: 0.0000e+00 - val_loss: 322.5815 - val_Lev: 0.0207\n","Epoch 2/400\n"]},{"name":"stderr","output_type":"stream","text":["2023-08-16 11:44:21.513659: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6040576609444454028\n","2023-08-16 11:44:21.513692: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 3468244295748485735\n","2023-08-16 11:44:21.513710: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 5431156295792000666\n","2023-08-16 11:44:21.513719: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 596353700622202772\n"]},{"name":"stdout","output_type":"stream","text":["116/241 [=============>................] - ETA: 28s - loss: 279.0172 - Lev: 0.0000e+00"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["---------------------------------------------------------------------------","KeyboardInterrupt                         Traceback (most recent call last)","Cell In[26], line 4\n      1 if 'config' not in globals():\n      2   config=CFG()\n----> 4 train(config,use_supplemental=False,use_chicago=False)\n      6 #from google.colab import runtime\n      7 #runtime.unassign()\n","Cell In[24], line 51, in train(config, experiment_id, use_supplemental, use_chicago)\n     47 num_train=num_train//2\n     49 num_valid=187*32\n---> 51 train_run(\n     52     train_files,\n     53     valid_files,\n     54     config,\n     55     num_train,\n     56     num_valid,\n     57     summary=True,\n     58     experiment_id=experiment_id,\n     59     use_tfrecords=True,\n     60 )\n","Cell In[23], line 151, in train_run(train_files, valid_files, config, num_train, num_valid, experiment_id, use_tfrecords, summary)\n    148     callbacks.append(tf.keras.callbacks.TerminateOnNaN())\n    149 # callbacks.append(validation_callback)\n--> 151 history = model.fit(\n    152     train_ds,\n    153     epochs=config.epochs - config.resume,\n    154     #steps_per_epoch=steps_per_epoch,\n    155     #validation_steps=num_valid // config.batch_size,\n    156     callbacks=callbacks,\n    157     validation_data=valid_ds,\n    158     verbose=config.verbose,\n    159 )\n    161 if config.save_output:  # reload the saved best weights checkpoint\n    162     saved_based_model = f\"{config.output_path}/{config.comment}-exp{experiment_id}-best.h5\"\n","File ~/code/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:61, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n     59 def error_handler(*args, **kwargs):\n     60     if not tf.debugging.is_traceback_filtering_enabled():\n---> 61         return fn(*args, **kwargs)\n     63     filtered_tb = None\n     64     try:\n","File ~/code/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:1742, in Model.fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\n   1734 with tf.profiler.experimental.Trace(\n   1735     \"train\",\n   1736     epoch_num=epoch,\n   (...)\n   1739     _r=1,\n   1740 ):\n   1741     callbacks.on_train_batch_begin(step)\n-> 1742     tmp_logs = self.train_function(iterator)\n   1743     if data_handler.should_sync:\n   1744         context.async_wait()\n","File ~/code/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:141, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n    139 try:\n    140   if not is_traceback_filtering_enabled():\n--> 141     return fn(*args, **kwargs)\n    142 except NameError:\n    143   # In some very rare cases,\n    144   # `is_traceback_filtering_enabled` (from the outer scope) may not be\n    145   # accessible from inside this function\n    146   return fn(*args, **kwargs)\n","File ~/code/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825, in Function.__call__(self, *args, **kwds)\n    822 compiler = \"xla\" if self._jit_compile else \"nonXla\"\n    824 with OptionalXlaContext(self._jit_compile):\n--> 825   result = self._call(*args, **kwds)\n    827 new_tracing_count = self.experimental_get_tracing_count()\n    828 without_tracing = (tracing_count == new_tracing_count)\n","File ~/code/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857, in Function._call(self, *args, **kwds)\n    854   self._lock.release()\n    855   # In this case we have created variables on the first call, so we run the\n    856   # defunned version which is guaranteed to never create variables.\n--> 857   return self._no_variable_creation_fn(*args, **kwds)  # pylint: disable=not-callable\n    858 elif self._variable_creation_fn is not None:\n    859   # Release the lock early so that multiple threads can perform the call\n    860   # in parallel.\n    861   self._lock.release()\n","File ~/code/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148, in TracingCompiler.__call__(self, *args, **kwargs)\n    145 with self._lock:\n    146   (concrete_function,\n    147    filtered_flat_args) = self._maybe_define_function(args, kwargs)\n--> 148 return concrete_function._call_flat(\n    149     filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n","File ~/code/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349, in ConcreteFunction._call_flat(self, args, captured_inputs)\n   1345 possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n   1346 if (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n   1347     and executing_eagerly):\n   1348   # No tape is watching; skip to running the function.\n-> 1349   return self._build_call_outputs(self._inference_function(*args))\n   1350 forward_backward = self._select_forward_and_backward_functions(\n   1351     args,\n   1352     possible_gradient_type,\n   1353     executing_eagerly)\n   1354 forward_function, args_with_tangents = forward_backward.forward()\n","File ~/code/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196, in AtomicFunction.__call__(self, *args)\n    194 with record.stop_recording():\n    195   if self._bound_context.executing_eagerly():\n--> 196     outputs = self._bound_context.call_function(\n    197         self.name,\n    198         list(args),\n    199         len(self.function_type.flat_outputs),\n    200     )\n    201   else:\n    202     outputs = make_call_op_in_graph(self, list(args))\n","File ~/code/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457, in Context.call_function(self, name, tensor_inputs, num_outputs)\n   1455 cancellation_context = cancellation.context()\n   1456 if cancellation_context is None:\n-> 1457   outputs = execute.execute(\n   1458       name.decode(\"utf-8\"),\n   1459       num_outputs=num_outputs,\n   1460       inputs=tensor_inputs,\n   1461       attrs=attrs,\n   1462       ctx=self,\n   1463   )\n   1464 else:\n   1465   outputs = execute.execute_with_cancellation(\n   1466       name.decode(\"utf-8\"),\n   1467       num_outputs=num_outputs,\n   (...)\n   1471       cancellation_manager=cancellation_context,\n   1472   )\n","File ~/code/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n     51 try:\n     52   ctx.ensure_initialized()\n---> 53   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n     54                                       inputs, attrs, num_outputs)\n     55 except core._NotOkStatusException as e:\n     56   if name is not None:\n","KeyboardInterrupt: "]}],"source":["if 'config' not in globals():\n","  config=CFG()\n","\n","train(config,use_supplemental=False,use_chicago=False)\n","\n","#from google.colab import runtime\n","#runtime.unassign()"]},{"cell_type":"markdown","metadata":{"id":"Cdtx5fW3-DPm"},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-uAqcPmSYi1-"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZWJM1IC5Yi1-"},"outputs":[],"source":["class InferModel(tf.Module):\n","    def __init__(self, model,config=CFG):\n","        super().__init__()\n","\n","        self.model = model\n","        self.max_len=config.max_len\n","\n","    @tf.function(\n","        input_signature=[tf.TensorSpec(shape=(None,Constants.NUM_INPUT_FEATURES), dtype=tf.float32, name=\"inputs\")]\n","    )\n","    def __call__(self, inputs):\n","        \"\"\"\n","        Applies the feature generation model and main model to the input tensor.\n","\n","        Args:\n","            inputs: Input tensor with shape (T, F).\n","\n","        Returns:\n","            A dictionary with a single key 'outputs' and corresponding output tensor.\n","        \"\"\"\n","        x=tf.cast(inputs,tf.float32)\n","        x = x[None] # trick to deal with empty frames\n","        x = tf.cond(tf.shape(x)[1] == 0, lambda: tf.zeros((1, 1, Constants.NUM_INPUT_FEATURES)), lambda: tf.identity(x))\n","        x = x[0]\n","        x = preprocess(x,max_len=self.max_len)\n","\n","        x = self.model(x[None],training=False)[0][0]\n","\n","        x=decode_phrase(x)\n","        x = tf.cond(tf.shape(x)[0] == 0, lambda: tf.zeros(1, tf.int64), lambda: tf.identity(x))\n","\n","        outputs=tf.one_hot(x,depth=59,dtype=tf.float32)\n","        return {\"outputs\": outputs}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7xpye2JQYi1_"},"outputs":[],"source":["\n","config=CFG\n","\n","model = get_model(\n","    max_len=config.max_len,\n","    output_dim=config.output_dim,\n","    dim=config.dim,\n","    input_pad=Constants.INPUT_PAD,\n",")\n","experiment_id=0\n","\n","saved_based_model = f\"{config.input_path}/aug13-swa/{config.comment}-exp{experiment_id}-SWA.h5\"\n","model.load_weights(saved_based_model)\n","print(f\"model with weights {saved_based_model}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jwxBqovnYi1_"},"outputs":[],"source":["# Sanity Check\n","import json\n","with open (\"/kaggle/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n","    character_map = json.load(f)\n","rev_character_map = {j:i for i,j in character_map.items()}\n","\n","infer_keras_model=InferModel(model)\n","\n","main_dir = config.input_path+\"/asl-fingerspelling\"\n","path = f'{main_dir}/train_landmarks/5414471.parquet'\n","cols=selected_columns(path)\n","df = pd.read_parquet(path, engine = 'auto', columns = cols)\n","seq_id=1816796431\n","seq=df.loc[seq_id]\n","data = seq[cols].to_numpy()\n","print(f'input shape: {data.shape}, dtype: {data.dtype}')\n","output = infer_keras_model(data)[\"outputs\"]\n","prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output, axis=1)])\n","\n","print(prediction_str)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YQM7GMtfYi1_"},"outputs":[],"source":["SAVED_MODEL_PATH=\"/kaggel/working/infer_model\"\n","\n","tf.saved_model.save(infer_keras_model,SAVED_MODEL_PATH)\n","keras_model_converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_PATH)\n","keras_model_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","keras_model_converter.target_spec.supported_types = [tf.float16]\n","#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n","#converter.allow_custom_ops=True\n","tflite_model = keras_model_converter.convert()\n","!mkdir \"/kaggle/working/submit\"\n","TFLITE_FILE_PATH=config.output_path+\"/submit/model.tflite\"\n","with open(TFLITE_FILE_PATH, \"wb\") as f:\n","    f.write(tflite_model)\n","\n","with open(config.output_path+'/submit/inference_args.json', 'w') as f:\n","     json.dump({ 'selected_columns': cols }, f)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2KNUGXjBYi2A"},"outputs":[],"source":["interpreter = tf.lite.Interpreter(TFLITE_FILE_PATH)\n","REQUIRED_SIGNATURE = \"serving_default\"\n","REQUIRED_OUTPUT = \"outputs\"\n","found_signatures = list(interpreter.get_signature_list().keys())\n","if REQUIRED_SIGNATURE not in found_signatures:\n","    print(\"Required input signature not found.\")\n","\n","prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n","output = prediction_fn(inputs=data)\n","prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n","print(prediction_str)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTeDBunuYi2A"},"outputs":[],"source":["!zip submission.zip \"/kaggle/working/submit/model.tflite\" \"/kaggle/working/submit/inference_args.json\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZWcEOwClYi2A"},"outputs":[],"source":["#!pip install /kaggle/input/tflite-wheels-2140/tflite_runtime_nightly-2.14.0.dev20230508-cp310-cp310-manylinux2014_x86_64.whl"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","\n","\n","import json\n","import pandas as pd\n","#import tflite_runtime.interpreter as tflite\n","import tensorflow.lite as tflite\n","import numpy as np\n","import time\n","from tqdm import tqdm\n","import Levenshtein as Lev\n","import glob\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["SEL_FEATURES = json.load(open('/kaggle/working/submit/inference_args.json'))['selected_columns']\n","\n","def load_relevant_data_subset(pq_path):\n","        return pd.read_parquet(pq_path, columns=SEL_FEATURES) #selected_columns)\n","\n","with open (\"/kaggle/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n","    character_map = json.load(f)\n","rev_character_map = {j:i for i,j in character_map.items()}\n","\n","\n","df_csv = pd.read_csv('/kaggle/input/asl-fingerspelling/train.csv')\n","\n","idx = 0\n","sample = df_csv.loc[idx]\n","loaded = load_relevant_data_subset('/kaggle/input/asl-fingerspelling/' + sample['path'])\n","loaded = loaded[loaded.index==sample['sequence_id']].values\n","print(loaded.shape)\n","frames = loaded"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["st = time.time()\n","count=0\n","model_time = 0\n","\n","N=0\n","D=0\n","\n","files=sorted(glob.glob('/kaggle/input/asl-fingerspelling/train_landmarks/*.parquet'))[:6]\n","for f in files:\n","    fid=int(f.split(\"/\")[-1].split(\".\")[0])\n","    df = load_relevant_data_subset(f)\n","    seq=df.index.drop_duplicates()\n","    for ind in tqdm(seq):\n","        sample=df_csv[(df_csv[\"sequence_id\"]==ind) & (df_csv[\"file_id\"]==fid)]\n","        #print(sample)\n","        loaded = df.loc[ind].values\n","        count+=1\n","        md_st = time.time()\n","\n","        # out = infer_keras_model(loaded)[\"outputs\"] # original model\n","\n","        out = prediction_fn(inputs=loaded)[REQUIRED_OUTPUT] # tflite\n","\n","        model_time += time.time() - md_st\n","\n","        prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(out, axis=1)])\n","        assert out.ndim==2\n","        assert out.shape[1]==59\n","        assert out.dtype==np.float32\n","        assert np.all(np.isfinite(out))\n","        s1=sample[\"phrase\"].item()\n","        s2=prediction_str\n","        n = len(s1)\n","        d = Lev.distance(s1,s2)\n","        N=N+n\n","        D=D+d\n","        #print(ind,s1,s2,n,d)\n","lev=(N-D)/N\n","print(f'Lev: {lev:.4f}')\n","print(f'Mean time: {(time.time() - st)/count:.3f}')\n","print(f'Mean time only infer: {model_time/count:.3f}')"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":["Vh1J_bDCYi13"],"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
